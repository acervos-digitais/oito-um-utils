{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamp Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from os import listdir, path\n",
    "\n",
    "CAMERA_DB_PATH = \"./metadata/cameras.json\"\n",
    "\n",
    "META_PATHS = [\n",
    "  \"./metadata/FULL-0801\",\n",
    "  \"./metadata/0801-1152\",\n",
    "  # \"./metadata/0801-1152\",\n",
    "]\n",
    "\n",
    "# makedirs(META_PATH_2, exist_ok=True)\n",
    "\n",
    "TZ_BR = timezone(timedelta(hours=-3))\n",
    "\n",
    "DATETIME_STR_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "DEFAULT_DATETIME = datetime.strptime(\"08012023000000-0300\", '%d%m%Y%H%M%S%z')\n",
    "DEFAULT_TIMESTAMP = int(DEFAULT_DATETIME.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_date(dt):\n",
    "  correct_year = DEFAULT_DATETIME.year == dt.year\n",
    "  correct_month = DEFAULT_DATETIME.month == dt.month\n",
    "  correct_day = DEFAULT_DATETIME.day == dt.day\n",
    "  return correct_year and correct_month and correct_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_str(ts):\n",
    "  return datetime.fromtimestamp(ts, tz=TZ_BR).strftime(DATETIME_STR_FORMAT)\n",
    "\n",
    "def datetime_str(dt):\n",
    "  return dt.strftime(DATETIME_STR_FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CAMERA_DB_PATH, \"r\") as f:\n",
    "  camera_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_data = []\n",
    "\n",
    "for io_dir in sorted(camera_data.keys()):\n",
    "  vid_dir_paths = [path.join(dir_path, io_dir) for dir_path in META_PATHS]\n",
    "  input_files = sorted([f for f in listdir(vid_dir_paths[0]) if f.endswith(\"json\")])\n",
    "  print(\"processing\", io_dir)\n",
    "\n",
    "  for io_file in input_files:\n",
    "    input_file_paths = [path.join(file_path, io_file) for file_path in vid_dir_paths]\n",
    "    input_file_objs = [open(input_file_path, \"r\") for input_file_path in input_file_paths]\n",
    "\n",
    "    mseeks = [json.load(fo)[\"seek\"] for fo in input_file_objs]\n",
    "    mdatetimes = [[datetime.fromtimestamp(ts, tz=TZ_BR) for (ts, _) in s] for s in mseeks]\n",
    "    mtimestamps = [[ts for (ts, _) in s] for s in mseeks]\n",
    "    mframes = [[f for (_, f) in s] for s in mseeks]\n",
    "\n",
    "    # check all methods have same number of timestamps\n",
    "    len_errors = [len(s) != len(mseeks[0]) for s in mseeks]\n",
    "    if any(len_errors):\n",
    "      error_lengths = [len(s) for s in mseeks]\n",
    "      print(io_file, \"lengths\", error_lengths, mseeks)\n",
    "      continue\n",
    "\n",
    "    # check if time == 00:00:00\n",
    "    time_errors = [[ts == DEFAULT_TIMESTAMP for ts in tss] for tss in mtimestamps]\n",
    "    time_error_counts = [sum(te) for te in time_errors]\n",
    "\n",
    "    if any(time_error_counts):\n",
    "      time_values = [[timestamp_str(ts) for ts in tss if ts == DEFAULT_TIMESTAMP] for tss in mtimestamps]\n",
    "      print(io_file, \"time\", time_error_counts, time_values)\n",
    "      # only for DEBUG\n",
    "      # continue\n",
    "\n",
    "    # check if date not 2023/01/08\n",
    "    date_errors = [[not correct_date(dt) for dt in dts] for dts in mdatetimes]\n",
    "    date_error_counts = [sum(dte) for dte in date_errors]\n",
    "\n",
    "    if any(date_error_counts):\n",
    "      date_values = [[datetime_str(dt) for dt in dts if not correct_date(dt)] for dts in mdatetimes]\n",
    "      print(io_file, \"date\", date_error_counts, date_values)\n",
    "      # only for DEBUG\n",
    "      # continue\n",
    "\n",
    "    # check if all methods have analyzed the same frames\n",
    "    frame_errors = [[[f0 != f1 for f0, f1 in zip(fs0, fs1)] for fs1 in mframes] for fs0 in mframes]    \n",
    "    frame_error_counts = [sum([sum(fe) for fe in fes]) for fes in frame_errors]\n",
    "\n",
    "    if any(frame_error_counts):\n",
    "      frame_values = [[[(f0, f1) for f0, f1 in zip(fs0, fs1) if f0 != f1] for fs1 in mframes] for fs0 in mframes]\n",
    "      print(io_file, \"frame\", frame_error_counts, frame_values)\n",
    "      # only for DEBUG\n",
    "      #continue\n",
    "\n",
    "    # check mismatch between pairs of stamps\n",
    "    stamp_errors = [[[ts0 != ts1 for ts0, ts1 in zip(tss0, tss1)] for tss1 in mtimestamps] for tss0 in mtimestamps]\n",
    "    stamp_error_counts = [sum([sum(pe) for pe in pes]) for pes in stamp_errors]\n",
    "\n",
    "    if any(stamp_error_counts):\n",
    "      stamp_values = [[[(timestamp_str(ts0), timestamp_str(ts1)) for ts0, ts1 in zip(tss0, tss1) if ts0 != ts1] for tss1 in mtimestamps] for tss0 in mtimestamps]\n",
    "      print(io_file, \"mismatch\", stamp_error_counts, stamp_values)\n",
    "      # only for DEBUG\n",
    "      # continue\n",
    "\n",
    "    # check monotonicity\n",
    "    mono_errors = [[ts1 < ts0 for ts0, ts1 in zip(tss[:-1], tss[1:])] for tss in mtimestamps]\n",
    "    mono_error_counts = [sum(me) for me in mono_errors]\n",
    "\n",
    "    if any(mono_error_counts):\n",
    "      mono_values = [[(timestamp_str(ts0), timestamp_str(ts1)) for ts0, ts1 in zip(tss[:-1], tss[1:]) if ts1 < ts0] for tss in mtimestamps]\n",
    "      print(io_file, \"monotonicity\", mono_error_counts, mono_values)\n",
    "      # only for DEBUG\n",
    "      # continue\n",
    "\n",
    "    # append error data\n",
    "    for i, p in enumerate(META_PATHS):\n",
    "      error_data.append({\n",
    "        \"method\": p.replace(\"./metadata/\", \"\"),\n",
    "        \"name\": io_file.replace(\".json\", \"\"),\n",
    "        \"camera\": io_dir,\n",
    "        \"time-error\": time_error_counts[i],\n",
    "        \"date-error\": date_error_counts[i],\n",
    "        \"frame-error\": frame_error_counts[i],\n",
    "        \"stamp-error\": stamp_error_counts[i],\n",
    "        \"mono-error\": mono_error_counts[i],\n",
    "      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = pd.DataFrame.from_records(error_data)\n",
    "\n",
    "non_error = [\"method\", \"name\", \"camera\"]\n",
    "\n",
    "methods = error_df[\"method\"].unique()\n",
    "cameras = error_df[\"camera\"].unique()\n",
    "files = error_df[\"name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_method = {m: error_df[error_df[\"method\"] == m] for m in methods}\n",
    "\n",
    "for m, df in by_method.items():\n",
    "  nrows = len(df.index)\n",
    "  nstamps = 17 * nrows\n",
    "  print(m, \":\", nrows, \"records,\", nstamps, \"timestamps\")\n",
    "  error_sums = df.drop(columns=non_error).sum().to_frame(name=\"sums\")\n",
    "  error_sums['pct'] = error_sums['sums'] / nstamps\n",
    "  print(error_sums)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
