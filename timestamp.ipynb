{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import subprocess\n",
    "import torch\n",
    "\n",
    "from datetime import datetime\n",
    "from multiprocessing import Process, JoinableQueue as Queue\n",
    "from os import listdir, makedirs, path\n",
    "from queue import Empty as QueueEmptyException\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "CAMERA_DB_PATH = \"./metadata/cameras.json\"\n",
    "\n",
    "VIDEO_PATH = \"../../vids/0801-1152\"\n",
    "VIDEO_DATA_PATH = \"./metadata/0801-1152\"\n",
    "\n",
    "OCR_MODEL = 'microsoft/trocr-large-printed'\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(OCR_MODEL)\n",
    "model = VisionEncoderDecoderModel.from_pretrained(OCR_MODEL).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CAMERA_DB_PATH, \"r\") as f:\n",
    "  camera_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATETIME_PATTERN = r'([0-9]{1,2})[ -/:]([0-9]{1,2})[ -/:](202[0-9])[ -/:]([0-9]{1,2})[ -/:]?([0-9]{1,2})[ -/:]?([0-9]{1,2})'\n",
    "TIME_PATTERN = r'([0-9]{2}):([0-9]{2}):([0-9]{2})'\n",
    "DATETIME_FORMAT = '%d%m%Y%H%M%S%z'\n",
    "\n",
    "def string_to_epoch(datetime_string):\n",
    "  datetime_string = re.sub(r\"[@CDOQcdo]\", \"0\", datetime_string)\n",
    "  try:\n",
    "    matches = list(re.search(DATETIME_PATTERN, datetime_string).groups())\n",
    "  except:\n",
    "    try:\n",
    "      matches = [\"08\", \"01\", \"2023\"] + list(re.search(TIME_PATTERN, datetime_string).groups())\n",
    "    except:\n",
    "      matches = [\"08\", \"01\", \"2023\", \"00\", \"00\", \"00\"]\n",
    "\n",
    "  matches = [('00'+m)[-2:] for m in matches]\n",
    "  matches[2] = ('20'+matches[2])[-4:]\n",
    "  matches[2] = re.sub(r\"202[0-9]\", r\"2023\", matches[2])\n",
    "  matches[4] = re.sub(r\"8([0-9])\", r\"3\\1\", matches[4])\n",
    "  matches[5] = re.sub(r\"8([0-9])\", r\"3\\1\", matches[5])\n",
    "  with_utc_offset = \"\".join(matches) + \"-0300\"\n",
    "\n",
    "  try:\n",
    "    dt = datetime.strptime(with_utc_offset, DATETIME_FORMAT)\n",
    "  except:\n",
    "    dt = datetime.strptime(\"08012023000000-0300\", DATETIME_FORMAT)\n",
    "\n",
    "  return int(dt.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stamp:\n",
    "  def __init__(self, seconds, timestamp):\n",
    "    self.timestamp = timestamp\n",
    "    self.seconds = seconds\n",
    "  def __str__(self):\n",
    "    return self.stamp().__str__()\n",
    "  def stamp(self):\n",
    "    return [self.timestamp, self.seconds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(vid, frame, n=7, step=1):\n",
    "  frame_count = vid.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "  start = frame - int(n / 2) * step\n",
    "  start = max(0, start)\n",
    "  start = min(start, frame_count - n * step)\n",
    "\n",
    "  frames = []\n",
    "  for i in range(n):\n",
    "    vid.set(cv2.CAP_PROP_POS_FRAMES, start + i * step)\n",
    "    _, frame = vid.read()\n",
    "    frames.append(frame)\n",
    "  return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_count(txts):\n",
    "  counts = {}\n",
    "  for txt in txts:\n",
    "    counts[txt] = counts.get(txt, 0) + 1\n",
    "  by_count = sorted([[k,v] for k,v in counts.items()], key=lambda x: x[1], reverse=True)\n",
    "  return by_count[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr(imgs, groups=1):\n",
    "  pixel_values = processor(images=imgs, return_tensors=\"pt\").pixel_values.to(device)\n",
    "  generated_ids = model.generate(pixel_values)\n",
    "  generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "  generated_groups = np.array(generated_text).reshape(groups, -1)\n",
    "  return [get_max_count(txts) for txts in generated_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_frame(frame, crop_x, crop_h):\n",
    "  return frame[0:crop_h, crop_x:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))\n",
    "\n",
    "def clean_frame(frame, crop_x, crop_h):\n",
    "  crop = frame[0:crop_h, crop_x:]\n",
    "  _, thresh = cv2.threshold(cv2.cvtColor(crop, cv2.COLOR_RGB2GRAY), 190, 255, cv2.THRESH_BINARY)\n",
    "  inv_er_di = cv2.dilate(cv2.erode(cv2.bitwise_not(thresh), morph_kernel), morph_kernel)\n",
    "  rgb = cv2.cvtColor(inv_er_di, cv2.COLOR_GRAY2RGB)\n",
    "  return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "def clean_frame_1(frame, crop_x, crop_h):\n",
    "  crop = frame[0:crop_h, crop_x:]\n",
    "  dilate_grey = cv2.cvtColor(cv2.dilate(crop, di_kernel), cv2.COLOR_RGB2GRAY)\n",
    "  _, thresh = cv2.threshold(dilate_grey, 200, 255, cv2.THRESH_BINARY)\n",
    "  blur_inv_rgb = cv2.cvtColor(cv2.bitwise_not(cv2.blur(thresh, (2, 2))), cv2.COLOR_GRAY2RGB)\n",
    "  return blur_inv_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stamps(vid, keyframes):\n",
    "  width = vid.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "  height = vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "  crop_x = int(width / 1.72)\n",
    "  crop_h = int(0.11 * height)\n",
    "  fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "  frame_seconds = [int(frame // fps) for frame in keyframes]\n",
    "\n",
    "  frames = [get_frames(vid, frame) for frame in keyframes]\n",
    "  ocr_frames = [f for fs in frames for f in fs]\n",
    "  imgs = [clean_frame(frame, crop_x, crop_h) for frame in ocr_frames]\n",
    "\n",
    "  dt_str = ocr(imgs, groups=len(keyframes))\n",
    "\n",
    "  return [Stamp(t, string_to_epoch(s)) for s,t in zip(dt_str, frame_seconds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for io_dir in sorted(camera_data.keys()):\n",
    "  input_dir_path = path.join(VIDEO_PATH, io_dir)\n",
    "  output_dir_path = path.join(VIDEO_DATA_PATH, io_dir)\n",
    "  input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "  makedirs(output_dir_path, exist_ok=True)\n",
    "\n",
    "  print(io_dir)\n",
    "  for io_file in input_files:\n",
    "    input_file_path = path.join(input_dir_path, io_file)\n",
    "    file_data_out_path = path.join(output_dir_path, io_file.replace(\"mp4\", \"json\"))\n",
    "\n",
    "    if path.exists(file_data_out_path):\n",
    "      continue\n",
    "\n",
    "    print(\"processing:\", io_file)\n",
    "\n",
    "    file_data = {\n",
    "      \"name\": io_file,\n",
    "      \"camera\": io_dir,\n",
    "    }\n",
    "\n",
    "    vid = None\n",
    "    if not (\"length_seconds\" in file_data and \"length_frames\" in file_data):\n",
    "      if vid is None:\n",
    "        vid = cv2.VideoCapture(input_file_path)\n",
    "\n",
    "      fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "      if not fps > 0:\n",
    "        continue\n",
    "\n",
    "      length_frames = vid.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "      file_data[\"length_frames\"] = int(length_frames)\n",
    "      file_data[\"length_seconds\"] = int(length_frames // fps)\n",
    "\n",
    "    if not (\"time_start\" in file_data and \"time_end\" in file_data):\n",
    "      if vid is None:\n",
    "        vid = cv2.VideoCapture(input_file_path)\n",
    "\n",
    "      fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "      length_frames = vid.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "      last_frame = length_frames - 1\n",
    "      length_seconds_fps = int(length_frames // fps)\n",
    "\n",
    "      num_keyframes = 16\n",
    "      keyframes_0 = [int(i * last_frame / num_keyframes) for i in range(num_keyframes // 2)]\n",
    "      keyframes_1 = [int(i * last_frame / num_keyframes) for i in range(num_keyframes // 2, num_keyframes + 1)]\n",
    "\n",
    "      stamps_0 = get_stamps(vid, keyframes_0)\n",
    "      stamps_1 = get_stamps(vid, keyframes_1)\n",
    "      stamps = stamps_0 + stamps_1\n",
    "\n",
    "      file_data[\"time_start\"] = stamps[0].timestamp\n",
    "      file_data[\"time_end\"] = stamps[-1].timestamp\n",
    "      file_data[\"continuous\"] = abs((stamps[-1].timestamp - stamps[0].timestamp) - length_seconds_fps) < 2\n",
    "      file_data[\"seek\"] = [s.stamp() for s in stamps]\n",
    "\n",
    "    if vid is not None:\n",
    "      vid.release()\n",
    "\n",
    "    with open(file_data_out_path, \"w\") as f:\n",
    "      json.dump(file_data, f)\n",
    "\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(input_file_path)\n",
    "fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "length_frames = vid.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "last_frame = length_frames - 1\n",
    "length_seconds_fps = int(length_frames // fps)\n",
    "\n",
    "frames_0 = get_frames(vid, 0, 7)\n",
    "frames_n = get_frames(vid, last_frame - 7, 7)\n",
    "\n",
    "rgb_0 = [f[0:75, 720:] for f in frames_0]\n",
    "rgb_n = [f[0:75, 720:] for f in frames_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pixel_values = processor(images=rgb_0, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "generated_ids = model.generate(pixel_values)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Stamping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stamp_center(vid, stamp_0, stamp_1):\n",
    "  diff_seconds = stamp_1.seconds - stamp_0.seconds\n",
    "  diff_timestamp = stamp_1.timestamp - stamp_0.timestamp\n",
    "\n",
    "  if (diff_seconds) > 1 and abs(diff_seconds - diff_timestamp) > 1:\n",
    "    center_seconds = (stamp_1.seconds + stamp_0.seconds) / 2 + stamp_0.seconds\n",
    "    center_frame = center_seconds * vid.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    stamp_c = get_stamps(vid, center_frame)\n",
    "\n",
    "    left_center = [] # stamp_center(vid, stamp_0, stamp_c)\n",
    "    right_center = [] # stamp_center(vid, stamp_c, stamp_1)\n",
    "\n",
    "    return left_center + [stamp_c] + right_center\n",
    "  else:\n",
    "    return []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
