{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from datetime import datetime\n",
    "from os import listdir, makedirs, path\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "CAMERA_DB_PATH = \"./metadata/cameras.json\"\n",
    "\n",
    "VIDEO_PATH = \"../../vids/0801-1152\"\n",
    "VIDEO_DATA_PATH = \"./metadata/0801-1152-crop-64\"\n",
    "\n",
    "OCR_MODEL = 'microsoft/trocr-large-printed'\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(OCR_MODEL)\n",
    "model = VisionEncoderDecoderModel.from_pretrained(OCR_MODEL).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CAMERA_DB_PATH, \"r\") as f:\n",
    "  camera_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATETIME_PATTERN = r'([0-9]{1,2})[ -/:]([0-9]{1,2})[ -/:](202[0-9])[ -/:]([0-9]{1,2})[ -/:]?([0-9]{1,2})[ -/:]?([0-9]{1,2})'\n",
    "TIME_PATTERN = r'([0-9]{2}):([0-9]{2}):([0-9]{2})'\n",
    "DATETIME_FORMAT = '%d%m%Y%H%M%S%z'\n",
    "\n",
    "ERROR_DATETIME = [\"01\", \"01\", \"2025\", \"00\", \"00\", \"00\"]\n",
    "\n",
    "def string_to_timestamp(datetime_string):\n",
    "  datetime_string = re.sub(r\"[@CDOQcdo]\", \"0\", datetime_string)\n",
    "  try:\n",
    "    matches = list(re.search(DATETIME_PATTERN, datetime_string).groups())\n",
    "  except:\n",
    "    try:\n",
    "      matches = [\"08\", \"01\", \"2023\"] + list(re.search(TIME_PATTERN, datetime_string).groups())\n",
    "    except:\n",
    "      matches = ERROR_DATETIME\n",
    "\n",
    "  matches = [('00'+m)[-2:] for m in matches]\n",
    "  matches[2] = ('20'+matches[2])[-4:]\n",
    "  matches[2] = re.sub(r\"202[0-9]\", r\"2023\", matches[2])\n",
    "  matches[4] = re.sub(r\"8([0-9])\", r\"3\\1\", matches[4])\n",
    "  matches[5] = re.sub(r\"8([0-9])\", r\"3\\1\", matches[5])\n",
    "  with_utc_offset = \"\".join(matches) + \"-0300\"\n",
    "\n",
    "  try:\n",
    "    dt = datetime.strptime(with_utc_offset, DATETIME_FORMAT)\n",
    "  except:\n",
    "    with_utc_offset = ''.join(ERROR_DATETIME) + \"-0300\"\n",
    "    dt = datetime.strptime(with_utc_offset, DATETIME_FORMAT)\n",
    "\n",
    "  return int(dt.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stamp:\n",
    "  def __init__(self, timestamp, seconds):\n",
    "    self.timestamp = timestamp\n",
    "    self.seconds = seconds\n",
    "  def __str__(self):\n",
    "    return self.stamp().__str__()\n",
    "  def stamp(self):\n",
    "    return [self.timestamp, self.seconds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(vid, frame, n=7, step=1):\n",
    "  frame_count = vid.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "  start = frame - int(n / 2) * step\n",
    "  start = max(0, start)\n",
    "  start = min(start, frame_count - n * step)\n",
    "\n",
    "  frames = []\n",
    "  for i in range(n):\n",
    "    vid.set(cv2.CAP_PROP_POS_FRAMES, start + i * step)\n",
    "    _, frame = vid.read()\n",
    "    frames.append(frame)\n",
    "  return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_count(txts):\n",
    "  counts = {}\n",
    "  for txt in txts:\n",
    "    counts[txt] = counts.get(txt, 0) + 1\n",
    "  by_count = sorted([[k,v] for k,v in counts.items()], key=lambda x: x[1], reverse=True)\n",
    "  return by_count[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr(imgs, groups=1):\n",
    "  pixel_values = processor(images=imgs, return_tensors=\"pt\").pixel_values.to(device)\n",
    "  generated_ids = model.generate(pixel_values)\n",
    "  generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "  generated_groups = np.array(generated_text).reshape(groups, -1)\n",
    "  return [get_max_count(txts) for txts in generated_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_frame(frame, crop_x0, crop_x1, crop_y0, crop_y1):\n",
    "  return frame[crop_y0:crop_y1, crop_x0:crop_x1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))\n",
    "\n",
    "def clean_frame(frame, crop_x0, crop_x1, crop_y0, crop_y1):\n",
    "  crop = frame[crop_y0:crop_y1, crop_x0:crop_x1]\n",
    "  _, thresh = cv2.threshold(cv2.cvtColor(crop, cv2.COLOR_RGB2GRAY), 190, 255, cv2.THRESH_BINARY)\n",
    "  inv_er_di = cv2.dilate(cv2.erode(cv2.bitwise_not(thresh), morph_kernel), morph_kernel)\n",
    "  rgb = cv2.cvtColor(inv_er_di, cv2.COLOR_GRAY2RGB)\n",
    "  return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stamps(vid, keyframes, prefun=crop_frame):\n",
    "  width = vid.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "  height = vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "  crop_x0 = int(0.58 * width)\n",
    "  crop_x1 = crop_x0 + int(0.4 * width)\n",
    "  crop_y0 = int(0.04 * height)\n",
    "  crop_y1 = crop_y0 + int(0.04 * height)\n",
    "\n",
    "  fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "  frame_seconds = [int(frame // fps) for frame in keyframes]\n",
    "\n",
    "  frames = [get_frames(vid, frame, n=5, step=2) for frame in keyframes]\n",
    "  ocr_frames = [f for fs in frames for f in fs]\n",
    "  imgs = [prefun(frame, crop_x0, crop_x1, crop_y0, crop_y1) for frame in ocr_frames]\n",
    "\n",
    "  dt_str = ocr(imgs, groups=len(keyframes))\n",
    "\n",
    "  return [Stamp(string_to_timestamp(s), t) for s,t in zip(dt_str, frame_seconds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_dt_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "for io_dir in sorted(camera_data.keys()):\n",
    "  input_dir_path = path.join(VIDEO_PATH, io_dir)\n",
    "  output_dir_path = path.join(VIDEO_DATA_PATH, io_dir)\n",
    "  input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "  makedirs(output_dir_path, exist_ok=True)\n",
    "\n",
    "  print(io_dir)\n",
    "  for io_file in input_files:\n",
    "    input_file_path = path.join(input_dir_path, io_file)\n",
    "    file_data_out_path = path.join(output_dir_path, io_file.replace(\"mp4\", \"json\"))\n",
    "\n",
    "    if path.exists(file_data_out_path):\n",
    "      continue\n",
    "\n",
    "    print(\"processing:\", io_file)\n",
    "\n",
    "    file_data = {\n",
    "      \"name\": io_file,\n",
    "      \"camera\": io_dir,\n",
    "    }\n",
    "\n",
    "    vid = None\n",
    "    if not (\"length_seconds\" in file_data and \"length_frames\" in file_data):\n",
    "      if vid is None:\n",
    "        vid = cv2.VideoCapture(input_file_path)\n",
    "\n",
    "      fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "      if not fps > 0:\n",
    "        continue\n",
    "\n",
    "      length_frames = vid.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "      file_data[\"length_frames\"] = int(length_frames)\n",
    "      file_data[\"length_seconds\"] = int(length_frames // fps)\n",
    "\n",
    "    if not (\"time_start\" in file_data and \"time_end\" in file_data):\n",
    "      if vid is None:\n",
    "        vid = cv2.VideoCapture(input_file_path)\n",
    "\n",
    "      fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "      length_frames = vid.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "      last_frame = length_frames - 1\n",
    "      length_seconds_fps = int(length_frames // fps)\n",
    "\n",
    "      num_keyframes = min(64, length_seconds_fps)\n",
    "      keyframes_per_group = min(16, length_seconds_fps)\n",
    "      keyframes_per_group = keyframes_per_group + 1 if (num_keyframes % keyframes_per_group) == 0 else keyframes_per_group\n",
    "      keyframe_idx_groups = [range(i, i + keyframes_per_group) for i in range(0, num_keyframes, keyframes_per_group)]\n",
    "      keyframe_groups = [[int(i * last_frame / num_keyframes) for i in kfs if i <= num_keyframes] for kfs in keyframe_idx_groups]\n",
    "\n",
    "      stamps = []\n",
    "      for kfs in keyframe_groups:\n",
    "        stamps = stamps + get_stamps(vid, kfs, prefun=crop_frame)\n",
    "\n",
    "      file_data[\"time_start\"] = stamps[0].timestamp\n",
    "      file_data[\"time_end\"] = stamps[-1].timestamp\n",
    "      file_data[\"continuous\"] = abs((stamps[-1].timestamp - stamps[0].timestamp) - length_seconds_fps) < 2\n",
    "      file_data[\"seek\"] = [s.stamp() for s in stamps]\n",
    "\n",
    "    if vid is not None:\n",
    "      vid.release()\n",
    "\n",
    "    with open(file_data_out_path, \"w\") as f:\n",
    "      json.dump(file_data, f)\n",
    "\n",
    "end_dt_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(\"DONE!\", init_dt_str, end_dt_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamp Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from os import listdir, path\n",
    "\n",
    "CAMERA_DB_PATH = \"./metadata/cameras.json\"\n",
    "VIDEO_DATA_PATH = \"./metadata/0801-1152-crop-64\"\n",
    "\n",
    "VIDEO_DB_PATH = path.join(VIDEO_DATA_PATH, \"videos.json\")\n",
    "SEEK_DB_PATH = path.join(VIDEO_DATA_PATH, \"seek.json\")\n",
    "\n",
    "TZ_BR = timezone(timedelta(hours=-3))\n",
    "\n",
    "ERROR_DATETIME = datetime.strptime(\"01012025000000-0300\", '%d%m%Y%H%M%S%z')\n",
    "MIN_DATETIME = datetime.strptime(\"07012023230000-0300\", '%d%m%Y%H%M%S%z')\n",
    "MAX_DATETIME = datetime.strptime(\"09012023010000-0300\", '%d%m%Y%H%M%S%z')\n",
    "\n",
    "ERROR_TIMESTAMP = int(ERROR_DATETIME.timestamp())\n",
    "MIN_TIMESTAMP = int(MIN_DATETIME.timestamp())\n",
    "MAX_TIMESTAMP = int(MAX_DATETIME.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CAMERA_DB_PATH, \"r\") as f:\n",
    "  camera_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_ranges = {}\n",
    "file_seeks = {}\n",
    "videos_info = {}\n",
    "\n",
    "for io_dir in sorted(camera_data.keys()):\n",
    "  input_dir_path = path.join(VIDEO_DATA_PATH, io_dir)\n",
    "  input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"json\")])\n",
    "\n",
    "  camera_ranges[io_dir] = []\n",
    "\n",
    "  for io_file in input_files:\n",
    "    input_file_path = path.join(input_dir_path, io_file)\n",
    "    video_file_name = io_file.replace(\"json\", \"mp4\")\n",
    "\n",
    "    with open(input_file_path, \"r\") as f:\n",
    "      video_data = json.load(f)\n",
    "\n",
    "    seek_data = video_data[\"seek\"]\n",
    "    seek_data_sorted = sorted(video_data[\"seek\"], key=lambda x: x[1])\n",
    "    is_continuous = video_data[\"continuous\"]\n",
    "\n",
    "    if is_continuous:\n",
    "      camera_ranges[io_dir].append((seek_data_sorted[0][0], seek_data_sorted[-1][0], video_file_name))\n",
    "      file_seeks[video_file_name] = [seek_data_sorted[0],  seek_data_sorted[-1]]\n",
    "\n",
    "    else:\n",
    "      unique_ts_dict = {}\n",
    "      for ts, s in seek_data:\n",
    "        if ts == ERROR_TIMESTAMP:\n",
    "          continue\n",
    "\n",
    "        if ts < MIN_TIMESTAMP or ts > MAX_TIMESTAMP:\n",
    "          mdt = datetime.fromtimestamp(ts, tz=TZ_BR).replace(year=2023, month=1, day=8)\n",
    "          ts = int(mdt.timestamp())\n",
    "\n",
    "        if ts not in unique_ts_dict:\n",
    "          unique_ts_dict[ts] = []\n",
    "        unique_ts_dict[ts].append(s)\n",
    "\n",
    "      # average non-unique timestamps\n",
    "      unique_ts_seek = sorted([(ts, sum(ss) // len(ss)) for ts,ss in unique_ts_dict.items()], key=lambda x:x[1])\n",
    "\n",
    "      non_redundant_seek = unique_ts_seek[:1]\n",
    "      for ts, s in unique_ts_seek[1:]:\n",
    "        ts0, s0 = non_redundant_seek[-1]\n",
    "        if ((ts - ts0) != (s - s0)) or ts == unique_ts_seek[-1][0]:\n",
    "          non_redundant_seek.append((ts,s))\n",
    "\n",
    "      camera_ranges[io_dir].append((non_redundant_seek[0][0], non_redundant_seek[-1][0], video_file_name))\n",
    "      file_seeks[video_file_name] = non_redundant_seek\n",
    "\n",
    "    video_data[\"seek\"] = file_seeks[video_file_name]\n",
    "    videos_info[video_file_name] = video_data\n",
    "\n",
    "  camera_ranges[io_dir].sort(key=lambda x: x[1], reverse=True)\n",
    "  # TODO: calculate and print overlapping ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(camera_ranges, separators=(',',':')).replace(\"]],\", \"]],\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(file_seeks, separators=(',',':')).replace(\"]],\", \"]],\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(videos_info, separators=(',',':')).replace(\"]]},\", \"]]},\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seek_info = {\n",
    "  \"ranges\": camera_ranges,\n",
    "  \"seeks\": file_seeks\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VIDEO_DB_PATH, \"w\") as f:\n",
    "  json.dump(videos_info, f, indent=2, separators=(',',':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SEEK_DB_PATH, \"w\") as f:\n",
    "  json.dump(seek_info, f, separators=(',',':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Stamping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stamp_center(vid, stamp_0, stamp_1):\n",
    "  diff_seconds = stamp_1.seconds - stamp_0.seconds\n",
    "  diff_timestamp = stamp_1.timestamp - stamp_0.timestamp\n",
    "\n",
    "  if (diff_seconds) > 1 and abs(diff_seconds - diff_timestamp) > 1:\n",
    "    center_seconds = (stamp_1.seconds + stamp_0.seconds) / 2 + stamp_0.seconds\n",
    "    center_frame = center_seconds * vid.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    stamp_c = get_stamps(vid, center_frame)\n",
    "\n",
    "    left_center = [] # stamp_center(vid, stamp_0, stamp_c)\n",
    "    right_center = [] # stamp_center(vid, stamp_c, stamp_1)\n",
    "\n",
    "    return left_center + [stamp_c] + right_center\n",
    "  else:\n",
    "    return []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
