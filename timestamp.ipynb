{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from datetime import datetime\n",
    "from os import listdir, makedirs, path\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "CAMERA_DB_PATH = \"./metadata/cameras.json\"\n",
    "\n",
    "VIDEO_PATH = \"../../vids/0801-1152\"\n",
    "VIDEO_DATA_PATH = \"./metadata/0801-1152\"\n",
    "\n",
    "OCR_MODEL = 'microsoft/trocr-large-printed'\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(OCR_MODEL)\n",
    "model = VisionEncoderDecoderModel.from_pretrained(OCR_MODEL).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CAMERA_DB_PATH, \"r\") as f:\n",
    "  camera_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATETIME_PATTERN = r'([0-9]{1,2})[ -/:]([0-9]{1,2})[ -/:](202[0-9])[ -/:]([0-9]{1,2})[ -/:]?([0-9]{1,2})[ -/:]?([0-9]{1,2})'\n",
    "TIME_PATTERN = r'([0-9]{2}):([0-9]{2}):([0-9]{2})'\n",
    "DATETIME_FORMAT = '%d%m%Y%H%M%S%z'\n",
    "\n",
    "ERROR_DATETIME = [\"01\", \"01\", \"2025\", \"00\", \"00\", \"00\"]\n",
    "\n",
    "def string_to_timestamp(datetime_string):\n",
    "  datetime_string = re.sub(r\"[@CDOQcdo]\", \"0\", datetime_string)\n",
    "  try:\n",
    "    matches = list(re.search(DATETIME_PATTERN, datetime_string).groups())\n",
    "  except:\n",
    "    try:\n",
    "      matches = [\"08\", \"01\", \"2023\"] + list(re.search(TIME_PATTERN, datetime_string).groups())\n",
    "    except:\n",
    "      matches = ERROR_DATETIME\n",
    "\n",
    "  matches = [('00'+m)[-2:] for m in matches]\n",
    "  matches[2] = ('20'+matches[2])[-4:]\n",
    "  matches[2] = re.sub(r\"202[0-9]\", r\"2023\", matches[2])\n",
    "  matches[4] = re.sub(r\"8([0-9])\", r\"3\\1\", matches[4])\n",
    "  matches[5] = re.sub(r\"8([0-9])\", r\"3\\1\", matches[5])\n",
    "  with_utc_offset = \"\".join(matches) + \"-0300\"\n",
    "\n",
    "  try:\n",
    "    dt = datetime.strptime(with_utc_offset, DATETIME_FORMAT)\n",
    "  except:\n",
    "    with_utc_offset = ''.join(ERROR_DATETIME) + \"-0300\"\n",
    "    dt = datetime.strptime(with_utc_offset, DATETIME_FORMAT)\n",
    "\n",
    "  return int(dt.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stamp:\n",
    "  def __init__(self, timestamp, seconds):\n",
    "    self.timestamp = timestamp\n",
    "    self.seconds = seconds\n",
    "  def __str__(self):\n",
    "    return self.stamp().__str__()\n",
    "  def stamp(self):\n",
    "    return [self.timestamp, self.seconds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(vid, frame, n=7, step=1):\n",
    "  frame_count = vid.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "  start = frame - int(n / 2) * step\n",
    "  start = max(0, start)\n",
    "  start = min(start, frame_count - n * step)\n",
    "\n",
    "  frames = []\n",
    "  for i in range(n):\n",
    "    vid.set(cv2.CAP_PROP_POS_FRAMES, start + i * step)\n",
    "    _, frame = vid.read()\n",
    "    frames.append(frame)\n",
    "  return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_count(txts):\n",
    "  counts = {}\n",
    "  for txt in txts:\n",
    "    counts[txt] = counts.get(txt, 0) + 1\n",
    "  by_count = sorted([[k,v] for k,v in counts.items()], key=lambda x: x[1], reverse=True)\n",
    "  return by_count[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr(imgs, groups=1):\n",
    "  pixel_values = processor(images=imgs, return_tensors=\"pt\").pixel_values.to(device)\n",
    "  generated_ids = model.generate(pixel_values)\n",
    "  generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "  generated_groups = np.array(generated_text).reshape(groups, -1)\n",
    "  return [get_max_count(txts) for txts in generated_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_frame(frame, crop_x0, crop_x1, crop_y0, crop_y1):\n",
    "  return frame[crop_y0:crop_y1, crop_x0:crop_x1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))\n",
    "\n",
    "def clean_frame(frame, crop_x0, crop_x1, crop_y0, crop_y1):\n",
    "  crop = frame[crop_y0:crop_y1, crop_x0:crop_x1]\n",
    "  _, thresh = cv2.threshold(cv2.cvtColor(crop, cv2.COLOR_RGB2GRAY), 190, 255, cv2.THRESH_BINARY)\n",
    "  inv_er_di = cv2.dilate(cv2.erode(cv2.bitwise_not(thresh), morph_kernel), morph_kernel)\n",
    "  rgb = cv2.cvtColor(inv_er_di, cv2.COLOR_GRAY2RGB)\n",
    "  return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stamps(vid, keyframes, prefun=crop_frame):\n",
    "  width = vid.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "  height = vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "  crop_x0 = int(0.58 * width)\n",
    "  crop_x1 = crop_x0 + int(0.4 * width)\n",
    "  crop_y0 = int(0.04 * height)\n",
    "  crop_y1 = crop_y0 + int(0.04 * height)\n",
    "\n",
    "  fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "  frame_seconds = [int(frame // fps) for frame in keyframes]\n",
    "\n",
    "  frames = [get_frames(vid, frame, n=5, step=2) for frame in keyframes]\n",
    "  ocr_frames = [f for fs in frames for f in fs]\n",
    "  imgs = [prefun(frame, crop_x0, crop_x1, crop_y0, crop_y1) for frame in ocr_frames]\n",
    "\n",
    "  dt_str = ocr(imgs, groups=len(keyframes))\n",
    "\n",
    "  return [Stamp(string_to_timestamp(s), t) for s,t in zip(dt_str, frame_seconds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_dt_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "for io_dir in sorted(camera_data.keys()):\n",
    "  input_dir_path = path.join(VIDEO_PATH, io_dir)\n",
    "  output_dir_path = path.join(VIDEO_DATA_PATH, io_dir)\n",
    "  input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "  makedirs(output_dir_path, exist_ok=True)\n",
    "\n",
    "  print(io_dir)\n",
    "  for io_file in input_files:\n",
    "    input_file_path = path.join(input_dir_path, io_file)\n",
    "    file_data_out_path = path.join(output_dir_path, io_file.replace(\"mp4\", \"json\"))\n",
    "\n",
    "    if path.exists(file_data_out_path):\n",
    "      continue\n",
    "\n",
    "    print(\"processing:\", io_file)\n",
    "\n",
    "    file_data = {\n",
    "      \"name\": io_file,\n",
    "      \"camera\": io_dir,\n",
    "    }\n",
    "\n",
    "    vid = None\n",
    "    if not (\"length_seconds\" in file_data and \"length_frames\" in file_data):\n",
    "      if vid is None:\n",
    "        vid = cv2.VideoCapture(input_file_path)\n",
    "\n",
    "      fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "      if not fps > 0:\n",
    "        continue\n",
    "\n",
    "      length_frames = vid.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "      file_data[\"length_frames\"] = int(length_frames)\n",
    "      file_data[\"length_seconds\"] = length_frames / fps\n",
    "      file_data[\"fps\"] = int(fps)\n",
    "\n",
    "    if not (\"time_start\" in file_data and \"time_end\" in file_data):\n",
    "      if vid is None:\n",
    "        vid = cv2.VideoCapture(input_file_path)\n",
    "\n",
    "      fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "      length_frames = vid.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "      last_frame = length_frames - 1\n",
    "      length_seconds_int = int(length_frames // fps)\n",
    "\n",
    "      num_keyframes = min(64, length_seconds_int)\n",
    "      keyframes_per_group = min(16, length_seconds_int)\n",
    "      keyframes_per_group = keyframes_per_group + 1 if (num_keyframes % keyframes_per_group) == 0 else keyframes_per_group\n",
    "      keyframe_idx_groups = [range(i, i + keyframes_per_group) for i in range(0, num_keyframes, keyframes_per_group)]\n",
    "      keyframe_groups = [[int(i * last_frame / num_keyframes) for i in kfs if i <= num_keyframes] for kfs in keyframe_idx_groups]\n",
    "\n",
    "      stamps = []\n",
    "      for kfs in keyframe_groups:\n",
    "        stamps = stamps + get_stamps(vid, kfs, prefun=crop_frame)\n",
    "\n",
    "      file_data[\"time_start\"] = stamps[0].timestamp\n",
    "      file_data[\"time_end\"] = stamps[-1].timestamp\n",
    "      file_data[\"continuous\"] = abs((stamps[-1].timestamp - stamps[0].timestamp) - length_seconds_int) < 2\n",
    "      file_data[\"seek\"] = [s.stamp() for s in stamps]\n",
    "\n",
    "    if vid is not None:\n",
    "      vid.release()\n",
    "\n",
    "    with open(file_data_out_path, \"w\") as f:\n",
    "      json.dump(file_data, f)\n",
    "\n",
    "end_dt_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(\"DONE!\", init_dt_str, end_dt_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamp Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from os import listdir, path\n",
    "\n",
    "CAMERA_DB_PATH = \"./metadata/cameras.json\"\n",
    "VIDEO_DATA_PATH = \"./metadata/0801-1152\"\n",
    "\n",
    "VIDEO_DB_PATH = path.join(VIDEO_DATA_PATH, \"videos.json\")\n",
    "SEEK_DB_PATH = path.join(VIDEO_DATA_PATH, \"seek.json\")\n",
    "\n",
    "TZ_BR = timezone(timedelta(hours=-3))\n",
    "\n",
    "ERROR_DATETIME = datetime.strptime(\"01012025000000-0300\", '%d%m%Y%H%M%S%z')\n",
    "MIN_DATETIME = datetime.strptime(\"07012023230000-0300\", '%d%m%Y%H%M%S%z')\n",
    "MAX_DATETIME = datetime.strptime(\"09012023010000-0300\", '%d%m%Y%H%M%S%z')\n",
    "\n",
    "ERROR_TIMESTAMP = int(ERROR_DATETIME.timestamp())\n",
    "MIN_TIMESTAMP = int(MIN_DATETIME.timestamp())\n",
    "MAX_TIMESTAMP = int(MAX_DATETIME.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsToText(ts):\n",
    "  mdt = datetime.fromtimestamp(ts, tz=TZ_BR)\n",
    "  return mdt.strftime('%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CAMERA_DB_PATH, \"r\") as f:\n",
    "  camera_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_ranges = {}\n",
    "file_seeks = {}\n",
    "videos_info = {}\n",
    "\n",
    "for io_dir in sorted(camera_data.keys()):\n",
    "  input_dir_path = path.join(VIDEO_DATA_PATH, io_dir)\n",
    "  input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"json\")])\n",
    "\n",
    "  camera_ranges[io_dir] = []\n",
    "\n",
    "  for io_file in input_files:\n",
    "    input_file_path = path.join(input_dir_path, io_file)\n",
    "    video_file_name = io_file.replace(\"json\", \"mp4\")\n",
    "\n",
    "    with open(input_file_path, \"r\") as f:\n",
    "      video_data = json.load(f)\n",
    "\n",
    "    seek_data = video_data[\"seek\"]\n",
    "    seek_data_sorted = sorted(video_data[\"seek\"], key=lambda x: x[1])\n",
    "    is_continuous = video_data[\"continuous\"]\n",
    "\n",
    "    ts0 = seek_data_sorted[0][0]\n",
    "    ts1 = seek_data_sorted[-1][0]\n",
    "\n",
    "    error_timestamp = ts0 == ERROR_TIMESTAMP or ts1 == ERROR_TIMESTAMP\n",
    "\n",
    "    if ts0 < MIN_TIMESTAMP or ts0 > MAX_TIMESTAMP:\n",
    "      mdt = datetime.fromtimestamp(ts0, tz=TZ_BR).replace(year=2023, month=1, day=8)\n",
    "      ts0 = int(mdt.timestamp())\n",
    "      video_data[\"time_start\"] = ts0\n",
    "    if ts1 < MIN_TIMESTAMP or ts1 > MAX_TIMESTAMP:\n",
    "      mdt = datetime.fromtimestamp(ts1, tz=TZ_BR).replace(year=2023, month=1, day=8)\n",
    "      ts1 = int(mdt.timestamp())\n",
    "      video_data[\"time_end\"] = ts1\n",
    "\n",
    "    almost_continuous = not error_timestamp and abs((ts1 - ts0) - video_data[\"length_seconds\"]) < 2\n",
    "\n",
    "    if is_continuous or almost_continuous:\n",
    "      video_data[\"continuous\"] = True\n",
    "      seek_data_sorted[0][0] = ts0\n",
    "      seek_data_sorted[-1][0] = ts1\n",
    "      camera_ranges[io_dir].append((seek_data_sorted[0][0], seek_data_sorted[-1][0], video_file_name))\n",
    "      file_seeks[video_file_name] = [seek_data_sorted[0],  seek_data_sorted[-1]]\n",
    "\n",
    "    else:\n",
    "      unique_ts_dict = {}\n",
    "      for ts, s in seek_data_sorted:\n",
    "        if ts < MIN_TIMESTAMP or ts > MAX_TIMESTAMP:\n",
    "          continue\n",
    "\n",
    "        if ts not in unique_ts_dict:\n",
    "          unique_ts_dict[ts] = []\n",
    "        unique_ts_dict[ts].append(s)\n",
    "\n",
    "      unique_ts_seek = sorted([(ts, min(ss)) for ts,ss in unique_ts_dict.items()], key=lambda x:x[1])\n",
    "      avg_ts = sum([ts for ts, _ in unique_ts_seek]) / len(unique_ts_seek)\n",
    "\n",
    "      non_redundant_seek = unique_ts_seek[:1]\n",
    "      for ts, s in unique_ts_seek[1:]:\n",
    "        ts0, s0 = non_redundant_seek[-1]\n",
    "        if ((ts - ts0) != (s - s0)) or ts == unique_ts_seek[-1][0]:\n",
    "          non_redundant_seek.append((ts,s))\n",
    "\n",
    "      non_redundant_consistent_seek = non_redundant_seek[:1] if len(non_redundant_seek) == 1 else []\n",
    "\n",
    "      ts0, s0 = non_redundant_seek[0]\n",
    "      for ts, s in non_redundant_seek[1:]:\n",
    "        ts_diff = ts - ts0\n",
    "        s_diff = s - s0\n",
    "\n",
    "        if (abs(ts_diff - s_diff) < 3600):\n",
    "          if len(non_redundant_consistent_seek) < 1:\n",
    "            non_redundant_consistent_seek.append((ts0, s0))\n",
    "          non_redundant_consistent_seek.append((ts, s))\n",
    "\n",
    "        else:\n",
    "          if abs(ts - avg_ts) < abs(ts0 - avg_ts):\n",
    "            non_redundant_consistent_seek.append((ts, s))\n",
    "          elif len(non_redundant_consistent_seek) < 1:\n",
    "            non_redundant_consistent_seek.append((ts0, s0))\n",
    "\n",
    "        ts0, s0 = non_redundant_consistent_seek[-1]\n",
    "\n",
    "      ts0, s0 = non_redundant_consistent_seek[0]\n",
    "      tsn, sn = non_redundant_consistent_seek[-1]\n",
    "      vid_len = video_data[\"length_seconds\"]\n",
    "\n",
    "      if s0 > 0:\n",
    "        non_redundant_consistent_seek.insert(0, (ts0 - s0, 0))\n",
    "\n",
    "      if sn < vid_len:\n",
    "        s_diff = vid_len - sn\n",
    "        non_redundant_consistent_seek.append((tsn + s_diff, vid_len))\n",
    "\n",
    "      if video_data[\"time_end\"] < video_data[\"time_start\"]:\n",
    "        video_data[\"time_end\"] = non_redundant_consistent_seek[-1][0]\n",
    "      if abs(video_data[\"time_start\"] - non_redundant_consistent_seek[0][0]) > 2:\n",
    "        video_data[\"time_start\"] = non_redundant_consistent_seek[0][0]\n",
    "\n",
    "      camera_ranges[io_dir].append((non_redundant_consistent_seek[0][0], non_redundant_consistent_seek[-1][0], video_file_name))\n",
    "      file_seeks[video_file_name] = non_redundant_consistent_seek\n",
    "\n",
    "    video_data[\"seek\"] = file_seeks[video_file_name]\n",
    "    videos_info[video_file_name] = video_data\n",
    "\n",
    "  camera_ranges[io_dir].sort(key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(camera_ranges, separators=(',',':')).replace(\"]],\", \"]],\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(file_seeks, separators=(',',':')).replace(\"]],\", \"]],\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(videos_info, separators=(',',':')).replace(\"]]},\", \"]]},\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seek_info = {\n",
    "  camera: {\n",
    "    \"camera\": camera,\n",
    "    \"ranges\": ranges,\n",
    "    \"seeks\": { fn: file_seeks[fn] for _, _, fn in ranges}\n",
    "  } for camera, ranges in camera_ranges.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VIDEO_DB_PATH, \"w\") as f:\n",
    "  json.dump(videos_info, f, separators=(',',':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SEEK_DB_PATH, \"w\") as f:\n",
    "  json.dump(seek_info, f, separators=(',',':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export frames by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from os import listdir, makedirs, path\n",
    "\n",
    "VIDEO_DATA_PATH = \"./metadata/0801-1152\"\n",
    "SEEK_DB_PATH = path.join(VIDEO_DATA_PATH, \"seek.json\")\n",
    "VIDEO_DB_PATH = path.join(VIDEO_DATA_PATH, \"videos.json\")\n",
    "\n",
    "VIDEO_PATH = \"../../vids/0801-500\"\n",
    "IMAGE_PATH = \"../../imgs/0801-500\"\n",
    "makedirs(IMAGE_PATH, exist_ok=True)\n",
    "\n",
    "MIN_DATETIME = datetime.strptime(\"08012023000000-0300\", '%d%m%Y%H%M%S%z')\n",
    "MIN_TIMESTAMP = int(MIN_DATETIME.timestamp())\n",
    "\n",
    "SKIP_INTERVAL_SEC = 15 * 60 # 10 * 60\n",
    "DAY_SEC = 24 * 60 * 60\n",
    "STAMPS = [MIN_TIMESTAMP + d for d in range(0, DAY_SEC, SKIP_INTERVAL_SEC)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SEEK_DB_PATH, \"r\") as f:\n",
    "  seek_data = json.load(f)\n",
    "\n",
    "with open(VIDEO_DB_PATH, \"r\") as f:\n",
    "  video_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestampToPosition(ts, ts0, ts1, pos0, pos1):\n",
    "  return ((ts - ts0) / (ts1 - ts0)) * (pos1 - pos0) + pos0\n",
    "\n",
    "def getFilename(ranges, seeks):\n",
    "  def getFilenameFromTimestamp(ts):\n",
    "    filename = \"\"\n",
    "    position = -1\n",
    "    for ts0, ts1, fn in ranges:\n",
    "      if ts >= ts0 and ts <= ts1:\n",
    "        filename = fn\n",
    "        break\n",
    "    if filename == \"\":\n",
    "      return filename, position\n",
    "\n",
    "    mSeek = seeks[filename]\n",
    "    ts0, pos0 = mSeek[0]\n",
    "    for ts1, pos1 in mSeek[1:]:\n",
    "      if ts >= ts0 and ts <= ts1:\n",
    "        position = timestampToPosition(ts, ts0, ts1, pos0, pos1)\n",
    "        break\n",
    "      else:\n",
    "        ts0, pos0 = ts1, pos1\n",
    "    return filename, position\n",
    "  return getFilenameFromTimestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export images at equal intervals\n",
    "\n",
    "for cam in sorted(seek_data.keys()):\n",
    "  print(cam)\n",
    "  output_dir_path = path.join(IMAGE_PATH, cam)\n",
    "  makedirs(output_dir_path, exist_ok=True)\n",
    "\n",
    "  mRanges = seek_data[cam][\"ranges\"]\n",
    "  mSeeks = seek_data[cam][\"seeks\"]\n",
    "  mGetFilenameFromTimestamp = getFilename(mRanges, mSeeks)\n",
    "\n",
    "  for ts in STAMPS:\n",
    "    input_video_filename, offset_sec = mGetFilenameFromTimestamp(ts)\n",
    "    output_image_filename = f\"{ts}.jpg\"\n",
    "    output_image_path = path.join(output_dir_path, output_image_filename)\n",
    "    if input_video_filename != \"\":\n",
    "      input_video_path = path.join(VIDEO_PATH, cam, input_video_filename)\n",
    "      fps = video_data[input_video_filename][\"fps\"]\n",
    "      frameIdx = min(offset_sec * fps, video_data[input_video_filename][\"length_frames\"] - 1)\n",
    "\n",
    "      vid = cv2.VideoCapture(input_video_path)\n",
    "      vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "      vid.set(cv2.CAP_PROP_POS_FRAMES, frameIdx)\n",
    "      _, frame = vid.read()\n",
    "      cv2.imwrite(output_image_path, frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Timeline Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline_points = {}\n",
    "timeline_lines = {}\n",
    "\n",
    "for k,v in camera_ranges.items():\n",
    "  timeline_points[k] = []\n",
    "  timeline_lines[k] = []\n",
    "  for ts0, ts1, _ in v:\n",
    "    timeline_points[k].append(ts0)\n",
    "    timeline_points[k].append(ts1)\n",
    "    timeline_lines[k].append([ts0, ts1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(\n",
    "  k,\n",
    "  datetime.fromtimestamp(min(timeline_points[k]), tz=TZ_BR).strftime('%H:%M:%S'),\n",
    "  datetime.fromtimestamp(max(timeline_points[k]), tz=TZ_BR).strftime('%H:%M:%S')\n",
    "  ) \n",
    "  for k in timeline_points.keys()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(start=MIN_TIMESTAMP, stop=MAX_TIMESTAMP, num=14)\n",
    "xl = [datetime.fromtimestamp(ts, tz=TZ_BR).strftime('%H:%M') for ts in xs]\n",
    "\n",
    "ys = [-i*1e3 for i in range(len(timeline_points.keys()))]\n",
    "yl = [k[:2] for k in timeline_points.keys()]\n",
    "\n",
    "plt.rc('figure', figsize=(16, 12), dpi=80)\n",
    "plt.xticks(xs, xl)\n",
    "plt.yticks(ys, yl)\n",
    "plt.grid()\n",
    "\n",
    "for i,v in enumerate(timeline_lines.values()):\n",
    "  for x in v:\n",
    "    y = [-i*1e3] * len(x)\n",
    "    plt.plot(x, y, color='#1f77b4', marker='', linewidth=8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Stamping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stamp_center(vid, stamp_0, stamp_1):\n",
    "  diff_seconds = stamp_1.seconds - stamp_0.seconds\n",
    "  diff_timestamp = stamp_1.timestamp - stamp_0.timestamp\n",
    "\n",
    "  if (diff_seconds) > 1 and abs(diff_seconds - diff_timestamp) > 1:\n",
    "    center_seconds = (stamp_1.seconds + stamp_0.seconds) / 2 + stamp_0.seconds\n",
    "    center_frame = center_seconds * vid.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    stamp_c = get_stamps(vid, center_frame)\n",
    "\n",
    "    left_center = [] # stamp_center(vid, stamp_0, stamp_c)\n",
    "    right_center = [] # stamp_center(vid, stamp_c, stamp_1)\n",
    "\n",
    "    return left_center + [stamp_c] + right_center\n",
    "  else:\n",
    "    return []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
