{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyframe / Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import scipy.fftpack as fftpack\n",
    "\n",
    "from datetime import timedelta\n",
    "from os import listdir, makedirs, path\n",
    "\n",
    "from imagehash import ImageHash\n",
    "from PIL import Image as PImage\n",
    "\n",
    "VIDEO_PATH = \"../../vids/0801-500\"\n",
    "\n",
    "OUT_PATH = \"./metadata/keyframe-500\"\n",
    "makedirs(OUT_PATH, exist_ok=True)\n",
    "\n",
    "DIR_PATTERN = re.compile(\"^[0-3][0-9]-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "VIDEO_DB_PATH = \"./metadata/videos.json\"\n",
    "with open(VIDEO_DB_PATH, \"r\") as f:\n",
    "  video_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORNER_DIST_THOLD = 500\n",
    "\n",
    "def frameToTime(fi, fps):\n",
    "  return str(timedelta(seconds=(fi/fps)//1))\n",
    "\n",
    "def calculateDistance(P0, P1):\n",
    "  x0, y0 = P0.ravel()\n",
    "  x1, y1 = P1.ravel()\n",
    "  return ((x1 - x0) ** 2 + (y1 - y0) ** 2)\n",
    "\n",
    "def getFeatureMask(vw, vh):\n",
    "  mask_features = np.zeros((vh, vw), dtype=np.uint8)\n",
    "  mask_features[:vh//6, :vw//6] = 1\n",
    "  mask_features[-vh//5:, -vw//10:] = 1\n",
    "  mask_features[vh//2 - vh//20: vh//2 + vh//20,\n",
    "                vw//2 - vw//10: vw//2 + vw//10] = 1\n",
    "  return mask_features\n",
    "\n",
    "blur_size = (5,5)\n",
    "\n",
    "# Parameters for features to track\n",
    "feature_params = dict(maxCorners=100,\n",
    "                      qualityLevel=0.2,\n",
    "                      minDistance=3,\n",
    "                      blockSize=7)\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict(winSize=(15, 15),\n",
    "                 maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "hash_params = dict(\n",
    "  hash_size=8,\n",
    "  highfreq_factor=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perceptual hash function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phash(im, hash_size=8, highfreq_factor=4):\n",
    "    \"\"\"from vframe: https://github.com/vframeio/vframe/blob/master/src/vframe/utils/im_utils.py#L37-L48\"\"\"\n",
    "    \"\"\"Perceptual hash rewritten from https://github.com/JohannesBuchner/imagehash/blob/master/imagehash.py#L197\"\"\"\n",
    "    wh = hash_size * highfreq_factor\n",
    "    im = cv2.resize(im, (wh, wh), interpolation=cv2.INTER_NEAREST)\n",
    "    if len(im.shape) > 2 and im.shape[2] > 1:\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    mdct = fftpack.dct(fftpack.dct(im, axis=0), axis=1)\n",
    "    dctlowfreq = mdct[:hash_size, :hash_size]\n",
    "    med = np.median(dctlowfreq)\n",
    "    diff = dctlowfreq > med\n",
    "    return ImageHash(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dirs = sorted([d for d in listdir(VIDEO_PATH) if DIR_PATTERN.search(d) is not None])\n",
    "\n",
    "for io_dir in input_dirs[0:1]:\n",
    "  input_dir_path = path.join(VIDEO_PATH, io_dir)\n",
    "  input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "\n",
    "  vid = cv2.VideoCapture(path.join(input_dir_path, input_files[0]))\n",
    "  vw = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "  vh = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "  fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "  feature_mask = getFeatureMask(vw, vh)\n",
    "  diff_offset = 2 * vh // 9\n",
    "  vid.release()\n",
    "\n",
    "  for io_file in input_files[0:1]:\n",
    "    print(io_dir, io_file)\n",
    "    input_file_path = path.join(input_dir_path, io_file)\n",
    "    output_file_path = path.join(OUT_PATH, io_file.replace(\"mp4\", \"json\"))\n",
    "\n",
    "    vid = cv2.VideoCapture(input_file_path)\n",
    "    frame_count = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    _, prev_frame = vid.read()\n",
    "    prev_frame_hash = phash(prev_frame, **hash_params)\n",
    "    prev_frame_grey = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    prev_edges = cv2.blur(prev_frame_grey, blur_size).astype(np.int16)\n",
    "    prev_corners = cv2.goodFeaturesToTrack(prev_frame_grey, mask=feature_mask, **feature_params)\n",
    "\n",
    "    hash_size = prev_frame_hash.hash.size\n",
    "    frame_hash_threshold = hash_size // 2\n",
    "    static_hash_threshold = hash_size // 3\n",
    "\n",
    "    camera_sequences = []\n",
    "    action_sequences = []\n",
    "    static_sequences = []\n",
    "    static_hashes = []\n",
    "\n",
    "    for frameIdx in range(1, int(120*fps)):\n",
    "      _, frame = vid.read()\n",
    "      if frameIdx % 5 != 0:\n",
    "        continue\n",
    "\n",
    "      frame_grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "      if prev_corners is not None:\n",
    "        corners, _, _ = cv2.calcOpticalFlowPyrLK(prev_frame_grey, frame_grey, prev_corners, None, **lk_params)\n",
    "\n",
    "      valid_prev_corners = prev_corners is not None and len(prev_corners) > 0\n",
    "      valid_corners = corners is not None and len(corners) > 0\n",
    "\n",
    "      if valid_prev_corners and valid_corners:\n",
    "        corner_avg = np.array([calculateDistance(p0, p1) for p0,p1 in zip(corners, prev_corners)]).mean()\n",
    "      else:\n",
    "        corner_avg = 2 * CORNER_DIST_THOLD\n",
    "\n",
    "      camera_moved = corner_avg > CORNER_DIST_THOLD\n",
    "\n",
    "      if camera_moved:\n",
    "        if len(camera_sequences) == 0 or (frameIdx - camera_sequences[-1][1]) > fps:\n",
    "          camera_sequences.append([frameIdx, frameIdx])\n",
    "        else:\n",
    "          camera_sequences[-1][1] = frameIdx\n",
    "\n",
    "        prev_corners = cv2.goodFeaturesToTrack(frame_grey, mask=feature_mask, **feature_params)\n",
    "      else:\n",
    "        # grab static frames by hash independent of action\n",
    "        frame_hash = phash(frame, **hash_params)\n",
    "        if len(static_hashes) < 1:\n",
    "          static_hashes.append([frame_hash, frameIdx])\n",
    "        else:\n",
    "          frame_hash_diff = frame_hash - prev_frame_hash\n",
    "          static_hash_diff = frame_hash - static_hashes[-1][0]\n",
    "\n",
    "          if (frame_hash_diff < frame_hash_threshold and\n",
    "              static_hash_diff > static_hash_threshold):\n",
    "            static_hashes.append([frame_hash, frameIdx])\n",
    "\n",
    "        edges = cv2.blur(frame_grey, blur_size).astype(np.int16)\n",
    "        edge_diff = np.abs(edges - prev_edges)\n",
    "        edge_diff_avg = ((edge_diff > 8) * 255)[diff_offset:, :].mean()\n",
    "\n",
    "        if edge_diff_avg > 1.0:\n",
    "          if len(action_sequences) == 0 or (frameIdx - action_sequences[-1][1]) > fps:\n",
    "            action_sequences.append([frameIdx, frameIdx])\n",
    "          else: \n",
    "            action_sequences[-1][1] = frameIdx\n",
    "\n",
    "        prev_edges = edges.copy()\n",
    "        prev_frame_hash = ImageHash(frame_hash.hash)\n",
    "\n",
    "      prev_frame = frame.copy()\n",
    "      prev_frame_grey = frame_grey.copy()\n",
    "\n",
    "    # TODO: clean these up:\n",
    "    #   camera_sequences O(n)\n",
    "    #   action_sequences O(n)\n",
    "    #   static_hashes O(n^2)\n",
    "\n",
    "    vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_movement_pairs = [(frameToTime(f0, fps), frameToTime(f1, fps)) for f0,f1 in camera_sequences]\n",
    "static_frames = [frameToTime(f, fps) for h,f in static_hashes]\n",
    "static_frame_hashes = [str(h) for h,f in static_hashes]\n",
    "action_sequence_pairs = [(frameToTime(f0, fps), frameToTime(f1, fps)) for f0,f1 in action_sequences]\n",
    "\n",
    "print(camera_movement_pairs)\n",
    "print(len(static_hashes), static_frames)\n",
    "print(static_frame_hashes)\n",
    "print(action_sequence_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(input_file_path)\n",
    "for h,f in static_hashes:\n",
    "  vid.set(cv2.CAP_PROP_POS_FRAMES, f)\n",
    "  _, frame = vid.read()\n",
    "  print(frameToTime(f, fps), h)\n",
    "  display(PImage.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - reduce size of frames to around 160px (?)\n",
    "# - check accuracy vs size of image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkernel = np.ones((4, 4), np.uint8)\n",
    "ekernel = np.ones((4, 4), np.uint8)\n",
    "\n",
    "FRAME_NUM = 15*fps\n",
    "FRAME_DELTA = 5 # 10*60*fps\n",
    "\n",
    "vid = cv2.VideoCapture(input_file_path)\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, FRAME_NUM)\n",
    "_, prev_frame = vid.read()\n",
    "\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, FRAME_NUM + FRAME_DELTA)\n",
    "_, frame = vid.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_edges = cv2.blur(cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY), blur_size)\n",
    "edges = cv2.blur(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), blur_size)\n",
    "\n",
    "edge_diff = np.abs(edges.astype(np.int16) - prev_edges.astype(np.int16)).astype(np.uint8)\n",
    "edge_diff_erosion = ((edge_diff > 8) * 255).astype(np.uint8)[diff_offset:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (edge_diff.size, np.sum(edge_diff), np.mean(edge_diff)),\n",
    "    (edge_diff_erosion.size, np.sum(edge_diff_erosion), np.mean(edge_diff_erosion))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(PImage.fromarray(cv2.cvtColor(prev_frame, cv2.COLOR_BGR2RGB)))\n",
    "display(PImage.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))\n",
    "display(PImage.fromarray(cv2.cvtColor(prev_edges, cv2.COLOR_BGR2RGB)))\n",
    "display(PImage.fromarray(cv2.cvtColor(edges, cv2.COLOR_BGR2RGB)))\n",
    "\n",
    "display(PImage.fromarray(cv2.cvtColor(edge_diff, cv2.COLOR_BGR2RGB)))\n",
    "display(PImage.fromarray(cv2.cvtColor(edge_diff_erosion, cv2.COLOR_BGR2RGB)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkernel = np.ones((4, 4), np.uint8)\n",
    "ekernel = np.ones((4, 4), np.uint8)\n",
    "\n",
    "input_dirs = sorted([d for d in listdir(VIDEO_PATH) if DIR_PATTERN.search(d) is not None])\n",
    "input_dir_path = path.join(VIDEO_PATH, input_dirs[0])\n",
    "input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "input_file_path = path.join(input_dir_path, input_files[0])\n",
    "vid = cv2.VideoCapture(input_file_path)\n",
    "\n",
    "frame_count = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "vw = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "vh = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "print(vid.get(cv2.CAP_PROP_FPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "_, prev_frame = vid.read()\n",
    "prev_frame_grey = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "prev_corners = cv2.goodFeaturesToTrack(prev_frame_grey, **feature_params)\n",
    "\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, 1000)\n",
    "for frameIdx in range(0, 600):\n",
    "  _, frame = vid.read()\n",
    "  # edges = cv2.Canny(frame, 10, 100, 11)\n",
    "\n",
    "  corner_avg = 0\n",
    "  if prev_corners is not None:\n",
    "    corners, _, _ = cv2.calcOpticalFlowPyrLK(prev_frame, frame, prev_corners, None, **lk_params)\n",
    "    corner_avg = np.array([calculateDistance(p0, p1) for p0,p1 in zip(corners, prev_corners)]).mean()\n",
    "\n",
    "  if corner_avg > CORNER_DIST_THOLD or corner_avg == 0:\n",
    "    frame_grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    prev_corners = cv2.goodFeaturesToTrack(frame_grey, **feature_params)\n",
    "\n",
    "  prev_frame = frame.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SceneDetect\n",
    "https://www.scenedetect.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scenedetect import detect, AdaptiveDetector\n",
    "\n",
    "input_dirs = sorted([d for d in listdir(VIDEO_PATH) if DIR_PATTERN.search(d) is not None])\n",
    "\n",
    "for io_dir in input_dirs[1:2]:\n",
    "  input_dir_path = path.join(VIDEO_PATH, io_dir)\n",
    "  input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "  print(io_dir, input_files)\n",
    "\n",
    "  for io_file in input_files[:1]:\n",
    "    input_file_path = path.join(input_dir_path, io_file)\n",
    "    output_file_path = path.join(OUT_PATH, io_file.replace(\"mp4\", \"json\"))\n",
    "\n",
    "    scene_list = detect(input_file_path, AdaptiveDetector())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "9103",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
