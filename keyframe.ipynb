{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyframe / Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from datetime import timedelta\n",
    "from os import listdir, makedirs, path\n",
    "from scenedetect import detect, AdaptiveDetector\n",
    "\n",
    "from PIL import Image as PImage\n",
    "\n",
    "VIDEO_PATH = \"../../vids/0801-500\"\n",
    "\n",
    "OUT_PATH = \"./metadata/keyframe-500\"\n",
    "makedirs(OUT_PATH, exist_ok=True)\n",
    "\n",
    "DIR_PATTERN = re.compile(\"^[0-3][0-9]-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DB_PATH = \"./metadata/videos.json\"\n",
    "with open(VIDEO_DB_PATH, \"r\") as f:\n",
    "  video_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORNER_DIST_THOLD = 500\n",
    "\n",
    "VID_WIDTH = 500\n",
    "VID_HEIGHT = 282\n",
    "\n",
    "def frameToTime(fi, fps):\n",
    "  return str(timedelta(seconds=(fi/fps)//1))\n",
    "\n",
    "def calculateDistance(P0, P1):\n",
    "  x0, y0 = P0.ravel()\n",
    "  x1, y1 = P1.ravel()\n",
    "  return ((x1 - x0) ** 2 + (y1 - y0) ** 2)\n",
    "\n",
    "mask_features = np.zeros((VID_HEIGHT, VID_WIDTH), dtype=np.uint8)\n",
    "mask_features[:VID_HEIGHT//6, :VID_WIDTH//6] = 1\n",
    "mask_features[-VID_HEIGHT//5:, -VID_WIDTH//10:] = 1\n",
    "mask_features[VID_HEIGHT//2 - VID_HEIGHT//20: VID_HEIGHT//2 + VID_HEIGHT//10,\n",
    "              VID_WIDTH//2 - VID_WIDTH//10: VID_WIDTH//2 + VID_WIDTH//5] = 1\n",
    "\n",
    "# Parameters for features to track\n",
    "feature_params = dict(maxCorners=100,\n",
    "                      qualityLevel=0.2,\n",
    "                      minDistance=3,\n",
    "                      blockSize=7,\n",
    "                      mask=mask_features)\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict(winSize=(15, 15),\n",
    "                 maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dirs = sorted([d for d in listdir(VIDEO_PATH) if DIR_PATTERN.search(d) is not None])\n",
    "\n",
    "for io_dir in input_dirs[0:1]:\n",
    "  input_dir_path = path.join(VIDEO_PATH, io_dir)\n",
    "  input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "\n",
    "  for io_file in input_files[0:1]:\n",
    "    print(io_dir, io_file)\n",
    "    input_file_path = path.join(input_dir_path, io_file)\n",
    "    output_file_path = path.join(OUT_PATH, io_file.replace(\"mp4\", \"json\"))\n",
    "\n",
    "    vid = cv2.VideoCapture(input_file_path)\n",
    "    frame_count = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    _, prev_frame = vid.read()\n",
    "    prev_edges = cv2.Canny(prev_frame, 10, 100, 3)\n",
    "    prev_frame_grey = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    prev_corners = cv2.goodFeaturesToTrack(prev_frame_grey, **feature_params)\n",
    "\n",
    "    action_start = 0\n",
    "    action_end = 0\n",
    "\n",
    "    camera_movements = []\n",
    "\n",
    "    for frameIdx in range(1, int(120*fps)):\n",
    "      _, frame = vid.read()\n",
    "      frame_grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "      edges = cv2.Canny(frame, 10, 100, 11)\n",
    "\n",
    "      if prev_corners is not None:\n",
    "        corners, _, _ = cv2.calcOpticalFlowPyrLK(prev_frame_grey, frame_grey, prev_corners, None, **lk_params)\n",
    "\n",
    "      valid_prev_corners = prev_corners is not None and len(prev_corners) > 0\n",
    "      valid_corners = corners is not None and len(corners) > 0\n",
    "\n",
    "      corner_avg = 2 * CORNER_DIST_THOLD\n",
    "      if valid_prev_corners and valid_corners:\n",
    "        corner_avg = np.array([calculateDistance(p0, p1) for p0,p1 in zip(corners, prev_corners)]).mean()\n",
    "\n",
    "      corner_moved = corner_avg > CORNER_DIST_THOLD\n",
    "\n",
    "      if corner_moved:\n",
    "        if len(camera_movements) == 0 or (frameIdx - camera_movements[-1][1]) > 15:\n",
    "          camera_movements.append([frameIdx, frameIdx])\n",
    "        else:\n",
    "          camera_movements[-1][1] = frameIdx\n",
    "\n",
    "        if abs(action_end - action_start) > 5:\n",
    "          # TODO: save action range\n",
    "          pass\n",
    "\n",
    "        action_start = frameIdx\n",
    "        action_end = frameIdx\n",
    "\n",
    "        prev_corners = cv2.goodFeaturesToTrack(frame_grey, **feature_params)\n",
    "\n",
    "      # edge_diff = edges - prev_edges\n",
    "\n",
    "      prev_frame = frame.copy()\n",
    "      prev_frame_grey = frame_grey.copy()\n",
    "      # prev_edges = edges.copy()\n",
    "\n",
    "    camera_movement_pairs = [(frameToTime(f0, fps), frameToTime(f1, fps)) for f0,f1 in camera_movements]\n",
    "    print(camera_movement_pairs)\n",
    "\n",
    "# display(PImage.fromarray(frame))\n",
    "# display(PImage.fromarray(frame_grey))\n",
    "# display(PImage.fromarray(edges))\n",
    "# display(PImage.fromarray(prev_edges))\n",
    "# display(PImage.fromarray(edge_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - reduce size of frames to around 160px (?)\n",
    "\n",
    "# - threshold difference between consecutive frames\n",
    "# - compute a perceptual hash for each remaining frame and \n",
    "# - de-duplicate non-neighboring scenes using hash\n",
    "# - use canny edge representation to estimate sharpness quality\n",
    "\n",
    "# - check optical flow vs edge variance\n",
    "# - check accuracy vs size of image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dirs = sorted([d for d in listdir(VIDEO_PATH) if DIR_PATTERN.search(d) is not None])\n",
    "input_dir_path = path.join(VIDEO_PATH, input_dirs[0])\n",
    "input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "input_file_path = path.join(input_dir_path, input_files[0])\n",
    "vid = cv2.VideoCapture(input_file_path)\n",
    "frame_count = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(vid.get(cv2.CAP_PROP_FPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "_, prev_frame = vid.read()\n",
    "prev_frame_grey = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "prev_corners = cv2.goodFeaturesToTrack(prev_frame_grey, **feature_params)\n",
    "\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, 1000)\n",
    "for frameIdx in range(0, 600):\n",
    "  _, frame = vid.read()\n",
    "  # edges = cv2.Canny(frame, 10, 100, 11)\n",
    "\n",
    "  corner_avg = 0\n",
    "  if prev_corners is not None:\n",
    "    corners, _, _ = cv2.calcOpticalFlowPyrLK(prev_frame, frame, prev_corners, None, **lk_params)\n",
    "    corner_avg = np.array([calculateDistance(p0, p1) for p0,p1 in zip(corners, prev_corners)]).mean()\n",
    "\n",
    "  if corner_avg > CORNER_DIST_THOLD or corner_avg == 0:\n",
    "    frame_grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    prev_corners = cv2.goodFeaturesToTrack(frame_grey, **feature_params)\n",
    "\n",
    "  prev_frame = frame.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SceneDetect\n",
    "https://www.scenedetect.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dirs = sorted([d for d in listdir(VIDEO_PATH) if DIR_PATTERN.search(d) is not None])\n",
    "\n",
    "for io_dir in input_dirs[1:2]:\n",
    "  input_dir_path = path.join(VIDEO_PATH, io_dir)\n",
    "  input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "  print(io_dir, input_files)\n",
    "\n",
    "  for io_file in input_files[:1]:\n",
    "    input_file_path = path.join(input_dir_path, io_file)\n",
    "    output_file_path = path.join(OUT_PATH, io_file.replace(\"mp4\", \"json\"))\n",
    "\n",
    "    scene_list = detect(input_file_path, AdaptiveDetector())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "9103",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
