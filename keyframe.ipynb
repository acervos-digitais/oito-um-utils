{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyframe / Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from datetime import timedelta\n",
    "from os import listdir, makedirs, path\n",
    "from scenedetect import detect, AdaptiveDetector\n",
    "\n",
    "from PIL import Image as PImage\n",
    "\n",
    "VIDEO_PATH = \"../../vids/0801-500\"\n",
    "\n",
    "OUT_PATH = \"./metadata/keyframe-500\"\n",
    "makedirs(OUT_PATH, exist_ok=True)\n",
    "\n",
    "DIR_PATTERN = re.compile(\"^[0-3][0-9]-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DB_PATH = \"./metadata/videos.json\"\n",
    "with open(VIDEO_DB_PATH, \"r\") as f:\n",
    "  video_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORNER_DIST_THOLD = 500\n",
    "\n",
    "def frameToTime(fi, fps):\n",
    "  return str(timedelta(seconds=(fi/fps)//1))\n",
    "\n",
    "def calculateDistance(P0, P1):\n",
    "  x0, y0 = P0.ravel()\n",
    "  x1, y1 = P1.ravel()\n",
    "  return ((x1 - x0) ** 2 + (y1 - y0) ** 2)\n",
    "\n",
    "def getFeatureMask(vw, vh):\n",
    "  mask_features = np.zeros((vh, vw), dtype=np.uint8)\n",
    "  mask_features[:vh//6, :vw//6] = 1\n",
    "  mask_features[-vh//5:, -vw//10:] = 1\n",
    "  mask_features[vh//2 - vh//20: vh//2 + vh//20,\n",
    "                vw//2 - vw//10: vw//2 + vw//10] = 1\n",
    "  return mask_features\n",
    "\n",
    "# Canny parameters\n",
    "canny_params = dict(\n",
    "  threshold1=10,\n",
    "  threshold2=100,\n",
    "  apertureSize=3)\n",
    "\n",
    "# Parameters for features to track\n",
    "feature_params = dict(maxCorners=100,\n",
    "                      qualityLevel=0.2,\n",
    "                      minDistance=3,\n",
    "                      blockSize=7)\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict(winSize=(15, 15),\n",
    "                 maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### phash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phash(im, hash_size=8, highfreq_factor=4):\n",
    "    \"\"\"from vframe: https://github.com/vframeio/vframe/blob/master/src/vframe/utils/im_utils.py#L37-L48\"\"\"\n",
    "    \"\"\"Perceptual hash rewritten from https://github.com/JohannesBuchner/imagehash/blob/master/imagehash.py#L197\"\"\"\n",
    "    wh = hash_size * highfreq_factor\n",
    "    im = cv2.resize(im, (wh, wh), interpolation=cv2.INTER_NEAREST)\n",
    "    if len(im.shape) > 2 and im.shape[2] > 1:\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    mdct = fftpack.dct(fftpack.dct(im, axis=0), axis=1)\n",
    "    dctlowfreq = mdct[:hash_size, :hash_size]\n",
    "    med = np.median(dctlowfreq)\n",
    "    diff = dctlowfreq > med\n",
    "    return ImageHash(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dirs = sorted([d for d in listdir(VIDEO_PATH) if DIR_PATTERN.search(d) is not None])\n",
    "\n",
    "for io_dir in input_dirs[0:1]:\n",
    "  input_dir_path = path.join(VIDEO_PATH, io_dir)\n",
    "  input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "\n",
    "  vid = cv2.VideoCapture(path.join(input_dir_path, input_files[0]))\n",
    "  vid_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "  vid_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "  vid_mask = getFeatureMask(vid_width, vid_height)\n",
    "  vid.release()\n",
    "\n",
    "  for io_file in input_files[0:1]:\n",
    "    print(io_dir, io_file)\n",
    "    input_file_path = path.join(input_dir_path, io_file)\n",
    "    output_file_path = path.join(OUT_PATH, io_file.replace(\"mp4\", \"json\"))\n",
    "\n",
    "    vid = cv2.VideoCapture(input_file_path)\n",
    "    frame_count = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    _, prev_frame = vid.read()\n",
    "    prev_edges = cv2.Canny(prev_frame, **canny_params)\n",
    "    prev_frame_hash = phash(prev_frame)\n",
    "    prev_frame_grey = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    prev_corners = cv2.goodFeaturesToTrack(prev_frame_grey, mask=vid_mask, **feature_params)\n",
    "\n",
    "    action_start = 0\n",
    "    action_end = 0\n",
    "\n",
    "    camera_movements = []\n",
    "    static_hashes = []\n",
    "\n",
    "    for frameIdx in range(1, int(120*fps)):\n",
    "      _, frame = vid.read()\n",
    "      if frameIdx % 5 != 0:\n",
    "        continue\n",
    "\n",
    "      frame_grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "      if prev_corners is not None:\n",
    "        corners, _, _ = cv2.calcOpticalFlowPyrLK(prev_frame_grey, frame_grey, prev_corners, None, **lk_params)\n",
    "\n",
    "      valid_prev_corners = prev_corners is not None and len(prev_corners) > 0\n",
    "      valid_corners = corners is not None and len(corners) > 0\n",
    "\n",
    "      corner_avg = 2 * CORNER_DIST_THOLD\n",
    "      if valid_prev_corners and valid_corners:\n",
    "        corner_avg = np.array([calculateDistance(p0, p1) for p0,p1 in zip(corners, prev_corners)]).mean()\n",
    "\n",
    "      camera_moved = corner_avg > CORNER_DIST_THOLD\n",
    "\n",
    "      if camera_moved:\n",
    "        if len(camera_movements) == 0 or (frameIdx - camera_movements[-1][1]) > 15:\n",
    "          camera_movements.append([frameIdx, frameIdx])\n",
    "        else:\n",
    "          camera_movements[-1][1] = frameIdx\n",
    "\n",
    "        # push action\n",
    "        # if (action_end - action_start) > 15:\n",
    "        # action_sequences.append([action_start, action_end])\n",
    "        # action_start = frameIdx\n",
    "        # action_end = frameIdx\n",
    "\n",
    "        prev_corners = cv2.goodFeaturesToTrack(frame_grey, mask=vid_mask, **feature_params)\n",
    "      else:\n",
    "        # grab static frames by hash independent of action\n",
    "        # TODO: clean these up in post-processing with O(n^2)\n",
    "        frame_hash = phash(frame)\n",
    "        if len(static_hashes) < 1:\n",
    "          static_hashes.append([frame_hash, frameIdx])\n",
    "        else:\n",
    "          frame_hash_diff = frame_hash - prev_frame_hash\n",
    "          static_hash_diff = frame_hash - static_hashes[-1][0]\n",
    "          if frame_hash_diff < 30 and static_hash_diff > 12:\n",
    "            static_hashes.append([frame_hash, frameIdx])\n",
    "\n",
    "        edges = cv2.Canny(frame, **canny_params)\n",
    "        edge_diff = edges - prev_edges\n",
    "\n",
    "        # TODO: compute sum of pixels\n",
    "        # TODO: or hash of frame\n",
    "        # TODO: or hash of edges\n",
    "        edge_diff_sum = edge_diff.mean()\n",
    "\n",
    "        # TODO: threshold and detect static\n",
    "        static_frame = edge_diff_sum < 5\n",
    "\n",
    "        if static_frame:\n",
    "          # if (action_end - action_start) > 15:\n",
    "          # action_sequences.append([action_start, action_end])\n",
    "          # action_start = frameIdx\n",
    "          # action_end = frameIdx\n",
    "          pass\n",
    "        else:\n",
    "          # TODO: add some other criteria for actual movement\n",
    "          action_end = frameIdx\n",
    "\n",
    "        prev_edges = edges.copy()\n",
    "        prev_frame_hash = ImageHash(frame_hash.hash)\n",
    "\n",
    "      prev_frame = frame.copy()\n",
    "      prev_frame_grey = frame_grey.copy()\n",
    "\n",
    "    # possible_action = len(action_sequences) < 1 or action_start != action_sequences[-1][0]\n",
    "    # if possible_action and (action_end - action_start) > 15:\n",
    "    # action_sequences.append([action_start, action_end])\n",
    "\n",
    "    vid.release()\n",
    "    camera_movement_pairs = [(frameToTime(f0, fps), frameToTime(f1, fps)) for f0,f1 in camera_movements]\n",
    "    print(camera_movement_pairs)\n",
    "    static_frames = [frameToTime(f, fps) for h,f in static_hashes]\n",
    "    print(static_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - reduce size of frames to around 160px (?)\n",
    "\n",
    "# - threshold difference between consecutive frames\n",
    "# - compute a perceptual hash for each static frame\n",
    "\n",
    "# - check accuracy vs size of image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dirs = sorted([d for d in listdir(VIDEO_PATH) if DIR_PATTERN.search(d) is not None])\n",
    "input_dir_path = path.join(VIDEO_PATH, input_dirs[0])\n",
    "input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "input_file_path = path.join(input_dir_path, input_files[0])\n",
    "vid = cv2.VideoCapture(input_file_path)\n",
    "frame_count = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(vid.get(cv2.CAP_PROP_FPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "_, prev_frame = vid.read()\n",
    "prev_frame_grey = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "prev_corners = cv2.goodFeaturesToTrack(prev_frame_grey, **feature_params)\n",
    "\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, 1000)\n",
    "for frameIdx in range(0, 600):\n",
    "  _, frame = vid.read()\n",
    "  # edges = cv2.Canny(frame, 10, 100, 11)\n",
    "\n",
    "  corner_avg = 0\n",
    "  if prev_corners is not None:\n",
    "    corners, _, _ = cv2.calcOpticalFlowPyrLK(prev_frame, frame, prev_corners, None, **lk_params)\n",
    "    corner_avg = np.array([calculateDistance(p0, p1) for p0,p1 in zip(corners, prev_corners)]).mean()\n",
    "\n",
    "  if corner_avg > CORNER_DIST_THOLD or corner_avg == 0:\n",
    "    frame_grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    prev_corners = cv2.goodFeaturesToTrack(frame_grey, **feature_params)\n",
    "\n",
    "  prev_frame = frame.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SceneDetect\n",
    "https://www.scenedetect.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dirs = sorted([d for d in listdir(VIDEO_PATH) if DIR_PATTERN.search(d) is not None])\n",
    "\n",
    "for io_dir in input_dirs[1:2]:\n",
    "  input_dir_path = path.join(VIDEO_PATH, io_dir)\n",
    "  input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "  print(io_dir, input_files)\n",
    "\n",
    "  for io_file in input_files[:1]:\n",
    "    input_file_path = path.join(input_dir_path, io_file)\n",
    "    output_file_path = path.join(OUT_PATH, io_file.replace(\"mp4\", \"json\"))\n",
    "\n",
    "    scene_list = detect(input_file_path, AdaptiveDetector())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "9103",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
