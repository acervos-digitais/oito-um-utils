{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyframe / Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import scipy.fftpack as fftpack\n",
    "\n",
    "from datetime import timedelta\n",
    "from os import listdir, makedirs, path\n",
    "\n",
    "from imagehash import ImageHash\n",
    "from PIL import Image as PImage\n",
    "\n",
    "VIDEO_PATH = \"../../vids/0801-500\"\n",
    "\n",
    "OUT_PATH = \"./metadata/keyframe-500\"\n",
    "makedirs(OUT_PATH, exist_ok=True)\n",
    "\n",
    "DIR_PATTERN = re.compile(\"^[0-3][0-9]-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORNER_DIST_THOLD = 500\n",
    "\n",
    "def frameToTime(fi, fps):\n",
    "  seconds = int(fi / fps)\n",
    "  f_frames = round(fps * ((fi / fps) % 1))\n",
    "  return f\"{timedelta(seconds=seconds)}.{f_frames}\"\n",
    "\n",
    "def calculateDistance(P0, P1):\n",
    "  x0, y0 = P0.ravel()\n",
    "  x1, y1 = P1.ravel()\n",
    "  return ((x1 - x0) ** 2 + (y1 - y0) ** 2)\n",
    "\n",
    "def getFeatureMask(vw, vh):\n",
    "  mask_features = np.zeros((vh, vw), dtype=np.uint8)\n",
    "  mask_features[:vh//6, :vw//6] = 1\n",
    "  mask_features[-vh//5:, -vw//10:] = 1\n",
    "  mask_features[vh//2 - vh//20: vh//2 + vh//20,\n",
    "                vw//2 - vw//10: vw//2 + vw//10] = 1\n",
    "  return mask_features\n",
    "\n",
    "blur_size = (5,5)\n",
    "\n",
    "# Parameters for features to track\n",
    "feature_params = dict(maxCorners=100,\n",
    "                      qualityLevel=0.2,\n",
    "                      minDistance=3,\n",
    "                      blockSize=7)\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict(winSize=(15, 15),\n",
    "                 maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "hash_params = dict(\n",
    "  hash_size=8,\n",
    "  highfreq_factor=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phash(im, hash_size=8, highfreq_factor=4):\n",
    "  \"\"\"from vframe: https://github.com/vframeio/vframe/blob/master/src/vframe/utils/im_utils.py#L37-L48\"\"\"\n",
    "  \"\"\"Perceptual hash rewritten from https://github.com/JohannesBuchner/imagehash/blob/master/imagehash.py#L197\"\"\"\n",
    "  wh = hash_size * highfreq_factor\n",
    "  im = cv2.resize(im, (wh, wh), interpolation=cv2.INTER_NEAREST)\n",
    "  if len(im.shape) > 2 and im.shape[2] > 1:\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "  mdct = fftpack.dct(fftpack.dct(im, axis=0), axis=1)\n",
    "  dctlowfreq = mdct[:hash_size, :hash_size]\n",
    "  med = np.median(dctlowfreq)\n",
    "  diff = dctlowfreq > med\n",
    "  return ImageHash(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCornerDiffs(prev_frame, frame, vw, vh):\n",
    "  prev_edges = cv2.blur(prev_frame, blur_size).astype(np.int16)\n",
    "  edges = cv2.blur(frame, blur_size).astype(np.int16)\n",
    "\n",
    "  edge_diff = np.abs(edges - prev_edges)\n",
    "  edge_diff_erosion = ((edge_diff > 32) * 255)\n",
    "\n",
    "  T = edge_diff_erosion[:vh//40, :].mean()\n",
    "  B = edge_diff_erosion[-vh//40:, :].mean()\n",
    "  L = edge_diff_erosion[:, :vw//60].mean()\n",
    "  R = edge_diff_erosion[:, -vw//60:].mean()\n",
    "  return np.array([T, B, L, R])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_bw(frame, thold=1.0):\n",
    "  rvs = frame[:,:,0].astype(np.int16)\n",
    "  gvs = frame[:,:,1].astype(np.int16)\n",
    "  bvs = frame[:,:,2].astype(np.int16)\n",
    "  dsum = abs(rvs - gvs).sum() + abs(rvs - bvs).sum() + abs(gvs - bvs).sum()\n",
    "  davg = dsum / (frame.shape[0] * frame.shape[1])\n",
    "  return davg < thold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_seq(val, seqs):\n",
    "  nseqs = [val for f0,f1 in seqs if f0<=val and val<=f1]\n",
    "  return len(nseqs) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_hash(h0, hf_list, thold=4):\n",
    "  for h,_ in hf_list:\n",
    "    if abs(h - h0) < thold:\n",
    "      return True\n",
    "  return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Keyframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "input_dirs = sorted([d for d in listdir(VIDEO_PATH) if DIR_PATTERN.search(d) is not None])\n",
    "\n",
    "for io_dir in input_dirs:\n",
    "  output_dir_path = path.join(OUT_PATH, io_dir)\n",
    "  makedirs(output_dir_path, exist_ok=True)\n",
    "\n",
    "  input_dir_path = path.join(VIDEO_PATH, io_dir)\n",
    "  input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "\n",
    "  vid = cv2.VideoCapture(path.join(input_dir_path, input_files[0]))\n",
    "  vw = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "  vh = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "  feature_mask = getFeatureMask(vw, vh)\n",
    "  vid.release()\n",
    "\n",
    "  for io_file in input_files:\n",
    "    input_file_path = path.join(input_dir_path, io_file)\n",
    "    output_file_path = path.join(output_dir_path, io_file.replace(\"mp4\", \"json\"))\n",
    "\n",
    "    if path.isfile(output_file_path):\n",
    "      continue\n",
    "\n",
    "    print(io_dir, io_file)\n",
    "\n",
    "    vid = cv2.VideoCapture(input_file_path)\n",
    "    frame_count = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    _, prev_frame = vid.read()\n",
    "    prev_frame_hash = phash(prev_frame, **hash_params)\n",
    "    prev_frame_grey = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    prev_edges = cv2.blur(prev_frame_grey, blur_size).astype(np.int16)\n",
    "    prev_corners = cv2.goodFeaturesToTrack(prev_frame_grey, mask=feature_mask, **feature_params)\n",
    "\n",
    "    hash_size = prev_frame_hash.hash.size\n",
    "    frame_hash_threshold = hash_size // 2\n",
    "    static_hash_threshold = hash_size // 3\n",
    "\n",
    "    camera_sequences = []\n",
    "    action_sequences = []\n",
    "    static_hashes = []\n",
    "\n",
    "    for frameIdx in range(1, frame_count):\n",
    "      _, frame = vid.read()\n",
    "      if frameIdx % 5 != 0:\n",
    "        continue\n",
    "      if is_bw(frame):\n",
    "        continue\n",
    "\n",
    "      frame_grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "      if prev_corners is not None:\n",
    "        corners, _, _ = cv2.calcOpticalFlowPyrLK(prev_frame_grey, frame_grey, prev_corners, None, **lk_params)\n",
    "      else:\n",
    "        corners = None\n",
    "\n",
    "      valid_prev_corners = prev_corners is not None and len(prev_corners) > 0\n",
    "      valid_corners = corners is not None and len(corners) > 0\n",
    "\n",
    "      if valid_prev_corners and valid_corners:\n",
    "        corner_avg = np.array([calculateDistance(p0, p1) for p0,p1 in zip(corners, prev_corners)]).mean()\n",
    "      else:\n",
    "        corner_diffs = getCornerDiffs(prev_frame_grey, frame_grey, vw, vh)\n",
    "        corner_diffs_count = (corner_diffs > 200).sum()\n",
    "        if corner_diffs_count > 2:\n",
    "          corner_avg = 2 * CORNER_DIST_THOLD\n",
    "        else:\n",
    "          corner_avg = 0\n",
    "\n",
    "      camera_moved = corner_avg > CORNER_DIST_THOLD\n",
    "\n",
    "      if camera_moved:\n",
    "        if len(camera_sequences) == 0 or (frameIdx - camera_sequences[-1][1]) > fps:\n",
    "          camera_sequences.append([frameIdx, frameIdx])\n",
    "        else:\n",
    "          camera_sequences[-1][1] = frameIdx\n",
    "\n",
    "        prev_corners = cv2.goodFeaturesToTrack(frame_grey, mask=feature_mask, **feature_params)\n",
    "      else:\n",
    "        # grab static frames by hash independent of action\n",
    "        frame_hash = phash(frame, **hash_params)\n",
    "        if len(static_hashes) < 1:\n",
    "          static_hashes.append([frame_hash, frameIdx])\n",
    "        else:\n",
    "          frame_hash_diff = frame_hash - prev_frame_hash\n",
    "          static_hash_diff = frame_hash - static_hashes[-1][0]\n",
    "\n",
    "          if (frame_hash_diff < frame_hash_threshold and\n",
    "              static_hash_diff > static_hash_threshold and\n",
    "              int(str(frame_hash), 16) != 0 and\n",
    "              (not duplicate_hash(frame_hash, static_hashes))):\n",
    "            static_hashes.append([frame_hash, frameIdx])\n",
    "\n",
    "        edges = cv2.blur(frame_grey, blur_size).astype(np.int16)\n",
    "        edge_diff = np.abs(edges - prev_edges)\n",
    "        edge_diff_avg = ((edge_diff > 7) * 255).mean()\n",
    "\n",
    "        if edge_diff_avg > 1.0:\n",
    "          if len(action_sequences) == 0 or (frameIdx - action_sequences[-1][1]) > fps:\n",
    "            action_sequences.append([frameIdx, frameIdx])\n",
    "          else: \n",
    "            action_sequences[-1][1] = frameIdx\n",
    "\n",
    "        prev_edges = edges.copy()\n",
    "        prev_frame_hash = ImageHash(frame_hash.hash)\n",
    "\n",
    "      prev_frame = frame.copy()\n",
    "      prev_frame_grey = frame_grey.copy()\n",
    "\n",
    "    camera_sequences = [[f0, f1] for f0,f1 in camera_sequences if f0 != f1]\n",
    "    action_sequences = [[f0, f1] for f0,f1 in action_sequences if f0 != f1]\n",
    "\n",
    "    with open(output_file_path, \"w\") as of:\n",
    "      representative_frames = set()\n",
    "      foi_sum = 0\n",
    "\n",
    "      for _,f in static_hashes:\n",
    "        # DON'T skip static frames that are also in action seqs\n",
    "        # if not in_seq(f, action_sequences):\n",
    "        representative_frames.add(f)\n",
    "      for f0,f1 in action_sequences:\n",
    "        # skip action seqs that are also in camera seqs\n",
    "        if not (in_seq(f0, camera_sequences) and in_seq(f1, camera_sequences)):\n",
    "          representative_frames.add(f0)\n",
    "          representative_frames.add(f1)\n",
    "          foi_sum += abs(f1 - f0)\n",
    "\n",
    "      frame_data = {\n",
    "        \"camera_movement_sequences\": camera_sequences,\n",
    "        \"foi_sequences\": action_sequences,\n",
    "        \"foi_count_frames\": foi_sum,\n",
    "        \"foi_count_seconds\": foi_sum / fps,\n",
    "        \"foi_pct\": foi_sum / frame_count,\n",
    "        \"static_frames\": sorted([f for _,f in static_hashes]),\n",
    "        \"static_frames_count\": len([f for _,f in static_hashes]),\n",
    "        \"representative_frames\": sorted(representative_frames),\n",
    "        \"representative_frames_count\": len(representative_frames),\n",
    "      }\n",
    "\n",
    "      json.dump(frame_data, of, sort_keys=True)\n",
    "\n",
    "    vid.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Process (add to metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "from os import listdir, path\n",
    "\n",
    "VIDEO_DB_PATH_IN = \"./metadata/videos.json\"\n",
    "\n",
    "KEYFRAME_PATH = \"./metadata/keyframe-500\"\n",
    "VIDEO_DB_PATH_OUT = path.join(KEYFRAME_PATH, \"videos.json\")\n",
    "\n",
    "DIR_PATTERN = re.compile(\"^[0-3][0-9]-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open all keyframe files\n",
    "keyframe_data = {}\n",
    "\n",
    "input_dirs = sorted([d for d in listdir(KEYFRAME_PATH) if DIR_PATTERN.search(d) is not None])\n",
    "\n",
    "for io_dir in input_dirs:\n",
    "  input_dir_path = path.join(KEYFRAME_PATH, io_dir)\n",
    "  input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"json\")])\n",
    "\n",
    "  for io_file in input_files:\n",
    "    input_file_path = path.join(input_dir_path, io_file)\n",
    "    video_key = io_file.replace(\"json\", \"mp4\")\n",
    "    with open(input_file_path, \"r\") as f:\n",
    "      keyframe_data[video_key] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VIDEO_DB_PATH_IN, \"r\") as f:\n",
    "  video_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, vdata in video_data.items():\n",
    "  if k not in keyframe_data:\n",
    "    print(k, \"has no keyframe info\")\n",
    "  else:\n",
    "    video_data[k] = vdata | keyframe_data[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VIDEO_DB_PATH_OUT, \"w\") as f:\n",
    "  json.dump(video_data, f, separators=(',',':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_movement_pairs = [(frameToTime(f0, fps), frameToTime(f1, fps)) for f0,f1 in camera_sequences]\n",
    "action_sequence_pairs = [(frameToTime(f0, fps), frameToTime(f1, fps)) for f0,f1 in action_sequences]\n",
    "static_frames = [frameToTime(f, fps) for h,f in static_hashes]\n",
    "static_frame_hashes = [str(h) for h,f in static_hashes]\n",
    "\n",
    "print(camera_movement_pairs)\n",
    "print(action_sequence_pairs)\n",
    "print(len(static_hashes), static_frames)\n",
    "print(static_frame_hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(input_file_path)\n",
    "for h,f in static_hashes:\n",
    "  vid.set(cv2.CAP_PROP_POS_FRAMES, f)\n",
    "  _, frame = vid.read()\n",
    "  print(frameToTime(f, fps), h)\n",
    "  display(PImage.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algo Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dirs = sorted([d for d in listdir(VIDEO_PATH) if DIR_PATTERN.search(d) is not None])\n",
    "input_dir_path = path.join(VIDEO_PATH, input_dirs[0])\n",
    "input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "input_file_path = path.join(input_dir_path, input_files[5])\n",
    "\n",
    "vid = cv2.VideoCapture(input_file_path)\n",
    "vw = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "vh = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "feature_mask = getFeatureMask(vw, vh)\n",
    "frame_count = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "FRAME_NUM = 82*fps + 0\n",
    "FRAME_DELTA = 5\n",
    "\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, FRAME_NUM)\n",
    "_, prev_frame = vid.read()\n",
    "\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, FRAME_NUM + FRAME_DELTA)\n",
    "_, frame = vid.read()\n",
    "\n",
    "prev_frame_hash = phash(prev_frame, **hash_params)\n",
    "prev_frame_grey = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "prev_edges = cv2.blur(prev_frame_grey, blur_size).astype(np.int16)\n",
    "prev_corners = cv2.goodFeaturesToTrack(prev_frame_grey, mask=feature_mask, **feature_params)\n",
    "corners = None\n",
    "\n",
    "hash_size = prev_frame_hash.hash.size\n",
    "frame_hash_threshold = hash_size // 2\n",
    "static_hash_threshold = hash_size // 3\n",
    "\n",
    "frame_grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "if prev_corners is not None:\n",
    "  corners, _, _ = cv2.calcOpticalFlowPyrLK(prev_frame_grey, frame_grey, prev_corners, None, **lk_params)\n",
    "\n",
    "valid_prev_corners = prev_corners is not None and len(prev_corners) > 0\n",
    "valid_corners = corners is not None and len(corners) > 0\n",
    "\n",
    "if valid_prev_corners and valid_corners:\n",
    "  corner_avg = np.array([calculateDistance(p0, p1) for p0,p1 in zip(corners, prev_corners)]).mean()\n",
    "else:\n",
    "  print(frameToTime(frameIdx, fps), getCornerDiffs(prev_frame, frame, vw, vh))\n",
    "  corner_diffs = getCornerDiffs(prev_frame, frame, vw, vh)\n",
    "  corner_diffs_count = (corner_diffs > 128).sum()\n",
    "  corner_avg = 2 * CORNER_DIST_THOLD if corner_diffs_count > 2 else 0\n",
    "\n",
    "camera_moved = corner_avg > CORNER_DIST_THOLD\n",
    "\n",
    "frame_hash = phash(frame, **hash_params)\n",
    "\n",
    "frame_hash_diff = frame_hash - prev_frame_hash\n",
    "\n",
    "edges = cv2.blur(frame_grey, blur_size).astype(np.int16)\n",
    "edge_diff = np.abs(edges - prev_edges)\n",
    "edge_diff_avg = ((edge_diff > 7) * 255).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(PImage.fromarray(cv2.cvtColor(prev_frame, cv2.COLOR_BGR2RGB)))\n",
    "display(PImage.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))\n",
    "display(PImage.fromarray(cv2.cvtColor(prev_edges.astype(np.uint8), cv2.COLOR_BGR2RGB)))\n",
    "display(PImage.fromarray(cv2.cvtColor(edges.astype(np.uint8), cv2.COLOR_BGR2RGB)))\n",
    "display(PImage.fromarray(cv2.cvtColor(edge_diff.astype(np.uint8), cv2.COLOR_BGR2RGB)))\n",
    "display(PImage.fromarray(cv2.cvtColor(((edge_diff > 8) * 255).astype(np.uint8), cv2.COLOR_BGR2RGB)))\n",
    "\n",
    "print(\"valid_prev_corners\", valid_prev_corners, \"valid_corners\", valid_corners, \"camera_moved\", camera_moved)\n",
    "print(\"frame hash diff\", frame_hash_diff, \"thresh: <\", frame_hash_threshold, \" > \", static_hash_threshold)\n",
    "print(\"edge_diff_avg\", edge_diff_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B&W Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_bw(frame, thold=1.0):\n",
    "  rvs = frame[:,:,0].astype(np.int16)\n",
    "  gvs = frame[:,:,1].astype(np.int16)\n",
    "  bvs = frame[:,:,2].astype(np.int16)\n",
    "  rgd = abs(rvs - gvs).sum()\n",
    "  rbd = abs(rvs - bvs).sum()\n",
    "  gbd = abs(gvs - bvs).sum()\n",
    "  dsum = rgd + rbd + gbd\n",
    "  davg = dsum / (frame.shape[0] * frame.shape[1])\n",
    "  print(rgd, rbd, gbd, dsum, davg)\n",
    "  return davg < thold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dirs = sorted([d for d in listdir(VIDEO_PATH) if DIR_PATTERN.search(d) is not None])\n",
    "input_dir_path = path.join(VIDEO_PATH, input_dirs[0])\n",
    "input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "input_file_path = path.join(input_dir_path, input_files[0])\n",
    "\n",
    "vid = cv2.VideoCapture(input_file_path)\n",
    "fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "FRAME_NUM = 50*fps\n",
    "\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, FRAME_NUM)\n",
    "_, frame = vid.read()\n",
    "\n",
    "display(PImage.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))\n",
    "\n",
    "print(is_bw(frame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_NUM = 15*fps\n",
    "FRAME_DELTA = 5 # 10*60*fps\n",
    "\n",
    "vid = cv2.VideoCapture(input_file_path)\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, FRAME_NUM)\n",
    "_, prev_frame = vid.read()\n",
    "\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, FRAME_NUM + FRAME_DELTA)\n",
    "_, frame = vid.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_edges = cv2.blur(cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY), blur_size)\n",
    "edges = cv2.blur(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), blur_size)\n",
    "\n",
    "edge_diff = np.abs(edges.astype(np.int16) - prev_edges.astype(np.int16)).astype(np.uint8)\n",
    "edge_diff_erosion = ((edge_diff > 8) * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (edge_diff.size, np.sum(edge_diff), np.mean(edge_diff)),\n",
    "    (edge_diff_erosion.size, np.sum(edge_diff_erosion), np.mean(edge_diff_erosion))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(PImage.fromarray(cv2.cvtColor(prev_frame, cv2.COLOR_BGR2RGB)))\n",
    "display(PImage.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))\n",
    "display(PImage.fromarray(cv2.cvtColor(prev_edges, cv2.COLOR_BGR2RGB)))\n",
    "display(PImage.fromarray(cv2.cvtColor(edges, cv2.COLOR_BGR2RGB)))\n",
    "\n",
    "display(PImage.fromarray(cv2.cvtColor(edge_diff, cv2.COLOR_BGR2RGB)))\n",
    "display(PImage.fromarray(cv2.cvtColor(edge_diff_erosion, cv2.COLOR_BGR2RGB)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkernel = np.ones((4, 4), np.uint8)\n",
    "ekernel = np.ones((4, 4), np.uint8)\n",
    "\n",
    "input_dirs = sorted([d for d in listdir(VIDEO_PATH) if DIR_PATTERN.search(d) is not None])\n",
    "input_dir_path = path.join(VIDEO_PATH, input_dirs[0])\n",
    "input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "input_file_path = path.join(input_dir_path, input_files[0])\n",
    "vid = cv2.VideoCapture(input_file_path)\n",
    "\n",
    "frame_count = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "vw = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "vh = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "print(vid.get(cv2.CAP_PROP_FPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "_, prev_frame = vid.read()\n",
    "prev_frame_grey = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "prev_corners = cv2.goodFeaturesToTrack(prev_frame_grey, **feature_params)\n",
    "\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, 1000)\n",
    "for frameIdx in range(0, 600):\n",
    "  _, frame = vid.read()\n",
    "  # edges = cv2.Canny(frame, 10, 100, 11)\n",
    "\n",
    "  corner_avg = 0\n",
    "  if prev_corners is not None:\n",
    "    corners, _, _ = cv2.calcOpticalFlowPyrLK(prev_frame, frame, prev_corners, None, **lk_params)\n",
    "    corner_avg = np.array([calculateDistance(p0, p1) for p0,p1 in zip(corners, prev_corners)]).mean()\n",
    "\n",
    "  if corner_avg > CORNER_DIST_THOLD or corner_avg == 0:\n",
    "    frame_grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    prev_corners = cv2.goodFeaturesToTrack(frame_grey, **feature_params)\n",
    "\n",
    "  prev_frame = frame.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SceneDetect\n",
    "https://www.scenedetect.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scenedetect import detect, AdaptiveDetector\n",
    "\n",
    "input_dirs = sorted([d for d in listdir(VIDEO_PATH) if DIR_PATTERN.search(d) is not None])\n",
    "\n",
    "for io_dir in input_dirs[1:2]:\n",
    "  input_dir_path = path.join(VIDEO_PATH, io_dir)\n",
    "  input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "  print(io_dir, input_files)\n",
    "\n",
    "  for io_file in input_files[:1]:\n",
    "    input_file_path = path.join(input_dir_path, io_file)\n",
    "    output_file_path = path.join(OUT_PATH, io_file.replace(\"mp4\", \"json\"))\n",
    "\n",
    "    scene_list = detect(input_file_path, AdaptiveDetector())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
