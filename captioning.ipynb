{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Captioning / Scene Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from datetime import timedelta\n",
    "from os import listdir, makedirs, path\n",
    "\n",
    "from PIL import Image as PImage\n",
    "\n",
    "VIDEO_DB_PATH = \"./metadata/keyframe-500/videos.json\"\n",
    "\n",
    "VIDEO_PATH = \"../../vids/0801-500\"\n",
    "DIR_PATTERN = re.compile(\"^[0-3][0-9]-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Video Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VIDEO_DB_PATH, \"r\") as f:\n",
    "  video_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dirs = sorted([d for d in listdir(VIDEO_PATH) if DIR_PATTERN.search(d) is not None])\n",
    "\n",
    "for io_dir in input_dirs[:1]:\n",
    "  input_dir_path = path.join(VIDEO_PATH, io_dir)\n",
    "  input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "\n",
    "  for io_file in input_files:\n",
    "    if io_file not in video_data:\n",
    "      print(io_file, \"not in video_data\")\n",
    "      continue\n",
    "\n",
    "    print(io_dir, io_file)\n",
    "    input_file_path = path.join(input_dir_path, io_file)\n",
    "\n",
    "    vid = cv2.VideoCapture(input_file_path)\n",
    "    vw = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    vh = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_count = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "    rep_frames = video_data[io_file][\"representative_frames\"]\n",
    "\n",
    "    vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    for frame_data in rep_frames:\n",
    "      frameIdx = frame_data[\"index\"]\n",
    "      vid.set(cv2.CAP_PROP_POS_FRAMES, frameIdx)\n",
    "      _, frame = vid.read()\n",
    "      # TODO: magic goes here\n",
    "      frame_grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "      frame_data[\"caption\"] = \"\"\n",
    "\n",
    "    vid.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = sorted([d for d in listdir(VIDEO_PATH) if DIR_PATTERN.search(d) is not None])[0]\n",
    "input_dir_path = path.join(VIDEO_PATH, input_dir)\n",
    "input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])\n",
    "input_file_path = path.join(input_dir_path, input_files[3])\n",
    "\n",
    "vid = cv2.VideoCapture(input_file_path)\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, 10)\n",
    "_, frame = vid.read()\n",
    "\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "image = PImage.fromarray(frame)\n",
    "\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "MODELS = [\n",
    "  \"Salesforce/blip-image-captioning-base\",\n",
    "  \"Salesforce/blip-image-captioning-large\"\n",
    "]\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(MODELS[1])\n",
    "model = BlipForConditionalGeneration.from_pretrained(MODELS[1]).to(\"cuda\")\n",
    "\n",
    "inputs = processor(image, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "print(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "\n",
    "MODELS = [\n",
    "  \"microsoft/git-base\",\n",
    "  \"microsoft/git-large\",\n",
    "]\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(MODELS[1])\n",
    "model = AutoModelForCausalLM.from_pretrained(MODELS[1]).to(\"cuda\")\n",
    "\n",
    "pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values.to(\"cuda\")\n",
    "\n",
    "out = model.generate(pixel_values=pixel_values, max_length=50)\n",
    "caption = processor.batch_decode(out, skip_special_tokens=True)[0]\n",
    "print(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "\n",
    "MODELS = [\n",
    "  \"nlpconnect/vit-gpt2-image-captioning\"\n",
    "]\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained(MODELS[0]).to(\"cuda\")\n",
    "processor = ViTImageProcessor.from_pretrained(MODELS[0])\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODELS[0])\n",
    "\n",
    "pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values.to(\"cuda\")\n",
    "\n",
    "out = model.generate(pixel_values, max_length=48, num_beams=4)\n",
    "caption = tokenizer.batch_decode(out, skip_special_tokens=True)[0]\n",
    "print(caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = sorted([d for d in listdir(VIDEO_PATH) if DIR_PATTERN.search(d) is not None])[0]\n",
    "input_dir_path = path.join(VIDEO_PATH, input_dir)\n",
    "input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"mp4\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for io_file in input_files:\n",
    "  input_file_path = path.join(input_dir_path, io_file)\n",
    "  vid = cv2.VideoCapture(input_file_path)\n",
    "  rep_frames = video_data[io_file][\"representative_frames\"]\n",
    "\n",
    "  vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "  for frame_data in rep_frames:\n",
    "    frameIdx = frame_data[\"index\"]\n",
    "    vid.set(cv2.CAP_PROP_POS_FRAMES, frameIdx)\n",
    "    _, frame = vid.read()\n",
    "    frame_grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "  vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for io_file in input_files:\n",
    "  input_file_path = path.join(input_dir_path, io_file)\n",
    "  vid = cv2.VideoCapture(input_file_path)\n",
    "  rep_frames = video_data[io_file][\"representative_frames\"]\n",
    "  rep_frame_idxs = [f[\"index\"] for f in rep_frames]\n",
    "\n",
    "  vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "  for frameIdx in range(0, frame_count):\n",
    "    _, frame = vid.read()\n",
    "    if frameIdx not in rep_frame_idxs:\n",
    "      continue\n",
    "    else:\n",
    "      frame_grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "  vid.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Process (add to metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "from os import listdir, path\n",
    "\n",
    "VIDEO_DB_PATH = \"./metadata/videos.json\"\n",
    "CAPTION_PATH = \"./metadata/XXXX\"\n",
    "\n",
    "DIR_PATTERN = re.compile(\"^[0-3][0-9]-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open all caption files\n",
    "cap_data = {}\n",
    "\n",
    "input_dirs = sorted([d for d in listdir(CAPTION_PATH) if DIR_PATTERN.search(d) is not None])\n",
    "\n",
    "for io_dir in input_dirs:\n",
    "  input_dir_path = path.join(CAPTION_PATH, io_dir)\n",
    "  input_files = sorted([f for f in listdir(input_dir_path) if f.endswith(\"json\")])\n",
    "\n",
    "  for io_file in input_files:\n",
    "    input_file_path = path.join(input_dir_path, io_file)\n",
    "    video_key = io_file.replace(\"json\", \"mp4\")\n",
    "    with open(input_file_path, \"r\") as f:\n",
    "      cap_data[video_key] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VIDEO_DB_PATH, \"r\") as f:\n",
    "  video_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, vdata in video_data.items():\n",
    "  if k not in cap_data:\n",
    "    print(k, \"has no caption info\")\n",
    "  else:\n",
    "    for kk, kdata in cap_data[k].items():\n",
    "      video_data[k] = vdata | kdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VIDEO_DB_PATH, \"w\") as f:\n",
    "  json.dump(video_data, f, indent=2, separators=(',',':'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "9103",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
